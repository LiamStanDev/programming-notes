# 並發與性能優化

> 本章涵蓋 C++ 多線程編程、無鎖數據結構、內存優化、緩存優化等高性能技術,是構建低延遲交易系統的核心。

---

## 目錄

> **HFT 學習優先級**: ⭐⭐⭐ 必看 | ⭐⭐ 建議 | ⭐ 有空再看

1. [多線程基礎](#1-多線程基礎) ⭐⭐⭐
2. [同步原語](#2-同步原語) ⭐⭐
3. [原子操作與內存序](#3-原子操作與內存序) ⭐⭐⭐
4. [無鎖編程](#4-無鎖編程) ⭐⭐⭐
5. [緩存優化](#5-緩存優化) ⭐⭐⭐
6. [線程池](#6-線程池) ⭐⭐
7. [性能測量](#7-性能測量) ⭐⭐⭐
8. [異步編程與協程](#8-異步編程與協程) ⭐⭐

> **注意**: 關於 CPU 親和性與實時調度,請參考 `06-Linux系統編程與調優.md`。

---

## 1. 多線程基礎

### 1.1 std::thread 基本使用

```cpp
#include <thread>
#include <iostream>

void worker(int id) {
    std::cout << "Thread " << id << " running\n";
}

void thread_basics() {
    // 創建線程
    std::thread t1(worker, 1);
    std::thread t2(worker, 2);

    // Lambda 線程
    std::thread t3([]() {
        std::cout << "Lambda thread\n";
    });

    // 等待線程結束
    t1.join();
    t2.join();
    t3.join();

    // 分離線程 (不推薦)
    std::thread t4(worker, 4);
    t4.detach();  // 線程獨立運行
}
```

### 1.2 thread_local 存儲

```cpp
#include <thread>

thread_local int counter = 0;  // 每個線程獨立

void increment() {
    counter++;
    std::cout << "Thread " << std::this_thread::get_id()
              << " counter: " << counter << "\n";
}

void thread_local_example() {
    std::thread t1([]() {
        for (int i = 0; i < 5; ++i) increment();
    });

    std::thread t2([]() {
        for (int i = 0; i < 5; ++i) increment();
    });

    t1.join();
    t2.join();
    // 每個線程的 counter 都是 5
}
```

---

## 2. 同步原語

### 2.1 std::mutex

```cpp
#include <mutex>
#include <thread>
#include <vector>

class Counter {
public:
    void increment() {
        std::lock_guard<std::mutex> lock(mutex_);
        ++count_;
    }

    int get() const {
        std::lock_guard<std::mutex> lock(mutex_);
        return count_;
    }

private:
    mutable std::mutex mutex_;
    int count_ = 0;
};

void mutex_example() {
    Counter counter;
    std::vector<std::thread> threads;

    for (int i = 0; i < 10; ++i) {
        threads.emplace_back([&counter]() {
            for (int j = 0; j < 1000; ++j) {
                counter.increment();
            }
        });
    }

    for (auto& t : threads) {
        t.join();
    }

    std::cout << "Final count: " << counter.get() << "\n";  // 10000
}
```

### 2.2 std::unique_lock

```cpp
#include <mutex>

void unique_lock_example() {
    std::mutex mtx;

    {
        std::unique_lock<std::mutex> lock(mtx);
        // 可以提前解鎖
        lock.unlock();
        // 做其他事情...
        lock.lock();  // 重新加鎖
    }  // 自動解鎖

    // 延遲加鎖
    std::unique_lock<std::mutex> lock(mtx, std::defer_lock);
    // ... 做其他事情 ...
    lock.lock();  // 現在才加鎖
}
```

### 2.3 std::condition_variable

```cpp
#include <condition_variable>
#include <queue>
#include <mutex>

template<typename T>
class ThreadSafeQueue {
public:
    void push(T value) {
        std::lock_guard<std::mutex> lock(mutex_);
        queue_.push(std::move(value));
        cv_.notify_one();
    }

    T pop() {
        std::unique_lock<std::mutex> lock(mutex_);
        cv_.wait(lock, [this]() { return !queue_.empty(); });
        T value = std::move(queue_.front());
        queue_.pop();
        return value;
    }

private:
    std::queue<T> queue_;
    std::mutex mutex_;
    std::condition_variable cv_;
};

void condition_variable_example() {
    ThreadSafeQueue<int> queue;

    // 生產者
    std::thread producer([&queue]() {
        for (int i = 0; i < 10; ++i) {
            queue.push(i);
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
        }
    });

    // 消費者
    std::thread consumer([&queue]() {
        for (int i = 0; i < 10; ++i) {
            int value = queue.pop();
            std::cout << "Consumed: " << value << "\n";
        }
    });

    producer.join();
    consumer.join();
}
```

---

## 3. 原子操作與內存序

### 3.1 std::atomic 基礎

```cpp
#include <atomic>
#include <thread>

void atomic_basics() {
    std::atomic<int> counter{0};

    std::thread t1([&counter]() {
        for (int i = 0; i < 1000; ++i) {
            counter++;  // 原子操作
        }
    });

    std::thread t2([&counter]() {
        for (int i = 0; i < 1000; ++i) {
            counter++;
        }
    });

    t1.join();
    t2.join();

    std::cout << "Counter: " << counter << "\n";  // 2000
}
```

### 3.2 Compare-And-Swap (CAS)

```cpp
#include <atomic>

void cas_example() {
    std::atomic<int> value{10};

    int expected = 10;
    int desired = 20;

    // 如果 value == expected,則設置為 desired
    bool success = value.compare_exchange_strong(expected, desired);

    if (success) {
        std::cout << "CAS succeeded, value is now " << value << "\n";
    } else {
        std::cout << "CAS failed, expected was " << expected << "\n";
    }

    // weak 版本 (可能虛假失敗,但更快)
    expected = 20;
    while (!value.compare_exchange_weak(expected, 30)) {
        // 重試
    }
}
```

### 3.3 內存序 (Memory Ordering)

```cpp
#include <atomic>
#include <thread>

std::atomic<int> data{0};
std::atomic<bool> ready{false};

void memory_ordering_example() {
    // 生產者
    std::thread producer([]() {
        data.store(42, std::memory_order_relaxed);
        ready.store(true, std::memory_order_release);  // Release
    });

    // 消費者
    std::thread consumer([]() {
        while (!ready.load(std::memory_order_acquire)) {  // Acquire
            // 等待
        }
        std::cout << "Data: " << data.load(std::memory_order_relaxed) << "\n";
    });

    producer.join();
    consumer.join();
}
```

**內存序類型:**

| 內存序                 | 保證     | 性能 | 使用場景 |
| ---------------------- | -------- | ---- | -------- |
| `memory_order_relaxed` | 無同步   | 最快 | 計數器   |
| `memory_order_acquire` | 讀取同步 | 快   | 消費者   |
| `memory_order_release` | 寫入同步 | 快   | 生產者   |
| `memory_order_acq_rel` | 讀寫同步 | 中等 | RMW 操作 |
| `memory_order_seq_cst` | 全局順序 | 最慢 | 默認     |

---

## 4. 無鎖編程

### 4.1 無鎖棧

```cpp
#include <atomic>
#include <memory>

template<typename T>
class LockFreeStack {
private:
    struct Node {
        T data;
        Node* next;
        Node(const T& d) : data(d), next(nullptr) {}
    };

    std::atomic<Node*> head_{nullptr};

public:
    void push(const T& data) {
        Node* new_node = new Node(data);
        new_node->next = head_.load(std::memory_order_relaxed);

        while (!head_.compare_exchange_weak(
            new_node->next, new_node,
            std::memory_order_release,
            std::memory_order_relaxed)) {
            // 重試
        }
    }

    bool pop(T& result) {
        Node* old_head = head_.load(std::memory_order_acquire);

        while (old_head && !head_.compare_exchange_weak(
            old_head, old_head->next,
            std::memory_order_release,
            std::memory_order_acquire)) {
            // 重試
        }

        if (old_head) {
            result = old_head->data;
            delete old_head;
            return true;
        }
        return false;
    }
};
```

### 4.2 SPSC 無鎖隊列 (單生產者單消費者)

**核心概念:**

SPSC (Single Producer Single Consumer) 隊列是 HFT 系統中**最重要的數據結構**之一:

- **無鎖設計**: 無需 mutex,極低延遲 (~10ns)
- **環形緩衝區**: 固定大小,無動態分配
- **單向通信**: 一個線程寫入,另一個線程讀取
- **內存序優化**: 使用 acquire-release 語義保證正確性

**為什麼 SPSC 適合 HFT:**

1. **極低延遲**: 無鎖操作,避免上下文切換
2. **可預測性**: 無競爭,無重試,延遲穩定
3. **緩存友好**: 生產者和消費者操作不同的緩存行
4. **零分配**: 預分配緩衝區,運行時無內存分配

```cpp
#include <atomic>
#include <array>
#include <iostream>

template<typename T, size_t Size>
class SPSCQueue {
public:
    SPSCQueue() : head_(0), tail_(0) {}

    // 生產者調用 (單線程)
    bool push(const T& item) {
        // 1. 讀取當前 tail (relaxed,因為只有生產者寫 tail)
        size_t current_tail = tail_.load(std::memory_order_relaxed);
        size_t next_tail = (current_tail + 1) % Size;

        // 2. 檢查隊列是否滿 (acquire,確保看到消費者的最新 head)
        if (next_tail == head_.load(std::memory_order_acquire)) {
            return false;  // 隊列滿
        }

        // 3. 寫入數據 (普通寫入,因為消費者不會讀取未發布的數據)
        buffer_[current_tail] = item;

        // 4. 發布新的 tail (release,確保數據寫入對消費者可見)
        tail_.store(next_tail, std::memory_order_release);
        return true;
    }

    // 消費者調用 (單線程)
    bool pop(T& item) {
        // 1. 讀取當前 head (relaxed,因為只有消費者寫 head)
        size_t current_head = head_.load(std::memory_order_relaxed);

        // 2. 檢查隊列是否空 (acquire,確保看到生產者的最新 tail)
        if (current_head == tail_.load(std::memory_order_acquire)) {
            return false;  // 隊列空
        }

        // 3. 讀取數據
        item = buffer_[current_head];

        // 4. 發布新的 head (release,確保消費完成對生產者可見)
        head_.store((current_head + 1) % Size, std::memory_order_release);
        return true;
    }

    // 查詢隊列大小 (近似值,可能不精確)
    size_t size() const {
        size_t head = head_.load(std::memory_order_acquire);
        size_t tail = tail_.load(std::memory_order_acquire);
        return (tail >= head) ? (tail - head) : (Size - head + tail);
    }

    bool empty() const {
        return head_.load(std::memory_order_acquire) ==
               tail_.load(std::memory_order_acquire);
    }

private:
    std::array<T, Size> buffer_;

    // 關鍵: 使用 alignas(64) 避免 False Sharing
    // head_ 和 tail_ 在不同的緩存行上
    alignas(64) std::atomic<size_t> head_;  // 消費者修改
    alignas(64) std::atomic<size_t> tail_;  // 生產者修改
};

void spsc_example() {
    SPSCQueue<int, 1024> queue;

    // 生產者線程
    std::thread producer([&queue]() {
        for (int i = 0; i < 1000; ++i) {
            while (!queue.push(i)) {
                // 隊列滿,重試 (在 HFT 中應避免這種情況)
                std::this_thread::yield();
            }
        }
        std::cout << "Producer finished\n";
    });

    // 消費者線程
    std::thread consumer([&queue]() {
        int value;
        int count = 0;
        while (count < 1000) {
            if (queue.pop(value)) {
                // 處理數據
                ++count;
            } else {
                // 隊列空,可以做其他事情或自旋等待
                std::this_thread::yield();
            }
        }
        std::cout << "Consumer finished\n";
    });

    producer.join();
    consumer.join();
}
```

**關鍵技術點解析:**

1. **內存序的選擇**:

   ```cpp
   // 生產者:
   tail_.load(std::memory_order_relaxed);   // 讀自己的變量,無需同步
   head_.load(std::memory_order_acquire);   // 讀消費者的變量,需要同步
   tail_.store(next, std::memory_order_release);  // 發布數據給消費者

   // 消費者:
   head_.load(std::memory_order_relaxed);   // 讀自己的變量,無需同步
   tail_.load(std::memory_order_acquire);   // 讀生產者的變量,需要同步
   head_.store(next, std::memory_order_release);  // 發布消費完成給生產者
   ```

2. **為什麼需要 alignas(64)**:

   ```
   沒有對齊 (False Sharing):
   ┌────────────────────────────────┐
   │  head_  │  tail_  │  ...       │  <- 同一緩存行 (64 bytes)
   └────────────────────────────────┘
      ↑          ↑
      消費者修改  生產者修改
      (緩存行失效,性能下降 10-100x!)

   使用 alignas(64):
   ┌────────────────────────────────┐
   │  head_  │  padding...          │  <- 緩存行 1
   └────────────────────────────────┘
   ┌────────────────────────────────┐
   │  tail_  │  padding...          │  <- 緩存行 2
   └────────────────────────────────┘
      (無 False Sharing,性能最優!)
   ```

3. **環形緩衝區的優勢**:

   ```cpp
   // 線性緩衝區 (需要移動數據或動態分配)
   ❌ push: 可能需要擴容 (動態分配)
   ❌ pop: 可能需要移動數據 (O(n))

   // 環形緩衝區 (固定大小,索引環繞)
   ✅ push: O(1),無分配
   ✅ pop: O(1),無移動
   ✅ 緩存友好: 連續內存訪問
   ```

4. **Acquire-Release 語義**:

   ```cpp
   // 生產者線程:
   buffer_[tail] = data;                    // 1. 寫入數據
   tail_.store(new_tail, memory_order_release);  // 2. 發布 (release)

   // 消費者線程:
   if (tail_.load(memory_order_acquire) != head_) {  // 3. 獲取 (acquire)
       data = buffer_[head];                // 4. 讀取數據
   }

   // 保證: 步驟 1 happens-before 步驟 4
   // 即消費者看到新的 tail 時,一定能看到對應的數據
   ```

**性能對比:**

| 隊列類型              | 延遲 (ns) | 吞吐量 (ops/s) | 適用場景               |
| --------------------- | --------- | -------------- | ---------------------- |
| std::queue + mutex    | ~100-500  | 10M            | 通用                   |
| std::queue + spinlock | ~50-100   | 50M            | 低競爭                 |
| SPSC 無鎖隊列         | ~10-20    | 100M+          | HFT (單生產者單消費者) |
| MPMC 無鎖隊列         | ~50-200   | 50M            | 多生產者多消費者       |

**HFT 應用場景:**

```cpp
// 市場數據接收線程 -> 策略引擎線程
SPSCQueue<MarketDataEvent, 65536> md_queue;

// 策略引擎線程 -> 訂單發送線程
SPSCQueue<OrderMessage, 65536> order_queue;

// 執行報告線程 -> 策略引擎線程
SPSCQueue<ExecutionReport, 65536> exec_queue;
```

**常見陷阱:**

```cpp
// ❌ 錯誤: 多個生產者
std::thread p1([&queue]() { queue.push(1); });
std::thread p2([&queue]() { queue.push(2); });  // 數據競爭!

// ❌ 錯誤: 隊列大小不是 2 的冪 (取模慢)
SPSCQueue<int, 1000> queue;  // 1000 % 運算較慢

// ✅ 正確: 使用 2 的冪 (可以用位運算優化)
SPSCQueue<int, 1024> queue;  // 1024 = 2^10,可用 & 1023 代替 %

// ✅ 更好: 使用位運算優化的版本
template<typename T, size_t Size>
class FastSPSCQueue {
    static_assert((Size & (Size - 1)) == 0, "Size must be power of 2");

    bool push(const T& item) {
        size_t next_tail = (tail_ + 1) & (Size - 1);  // 位運算代替取模
        // ...
    }
};
```

**實戰建議:**

1. **隊列大小選擇**:

   - 太小: 頻繁滿,生產者阻塞
   - 太大: 浪費內存,緩存不友好
   - 推薦: 64K-256K 元素 (根據消息大小調整)

2. **滿隊列處理**:

   ```cpp
   // ❌ 不好: 忙等待
   while (!queue.push(data)) {}

   // ✅ 更好: 記錄丟棄
   if (!queue.push(data)) {
       ++dropped_count;
       log_error("Queue full, dropping message");
   }

   // ✅ 最好: 背壓 (Backpressure)
   if (!queue.push(data)) {
       slow_down_producer();  // 降低生產速度
   }
   ```

3. **性能測量**:
   ```cpp
   // 測量端到端延遲
   auto start = rdtsc();  // CPU 時間戳計數器
   queue.push(data);
   // ... 消費者處理 ...
   auto end = rdtsc();
   latency_ns = (end - start) * ns_per_cycle;
   ```

---

## 5. 緩存優化

### 5.1 False Sharing 問題

```cpp
#include <thread>
#include <vector>

// ❌ 錯誤: False Sharing
struct BadCounter {
    int count1;  // 同一緩存行
    int count2;  // 同一緩存行
};

// ✅ 正確: 避免 False Sharing
struct alignas(64) GoodCounter {
    int count1;
    char padding[60];  // 填充到 64 字節 (緩存行大小)
    int count2;
};

// 或使用 alignas
struct AlignedCounter {
    alignas(64) int count1;
    alignas(64) int count2;
};

void false_sharing_benchmark() {
    BadCounter bad;
    GoodCounter good;

    // 測試 BadCounter (會有 false sharing)
    auto start = std::chrono::high_resolution_clock::now();
    std::thread t1([&bad]() {
        for (int i = 0; i < 100000000; ++i) {
            bad.count1++;
        }
    });
    std::thread t2([&bad]() {
        for (int i = 0; i < 100000000; ++i) {
            bad.count2++;
        }
    });
    t1.join();
    t2.join();
    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    std::cout << "BadCounter: " << duration.count() << " ms\n";

    // 測試 GoodCounter (無 false sharing)
    start = std::chrono::high_resolution_clock::now();
    std::thread t3([&good]() {
        for (int i = 0; i < 100000000; ++i) {
            good.count1++;
        }
    });
    std::thread t4([&good]() {
        for (int i = 0; i < 100000000; ++i) {
            good.count2++;
        }
    });
    t3.join();
    t4.join();
    end = std::chrono::high_resolution_clock::now();
    duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    std::cout << "GoodCounter: " << duration.count() << " ms\n";
}
```

### 5.2 預取 (Prefetching)

```cpp
#include <xmmintrin.h>  // SSE intrinsics

void prefetch_example() {
    const int N = 1000000;
    int* data = new int[N];

    // 初始化
    for (int i = 0; i < N; ++i) {
        data[i] = i;
    }

    // 帶預取的遍歷
    long long sum = 0;
    for (int i = 0; i < N; ++i) {
        // 預取下一個緩存行
        if (i + 64 < N) {
            _mm_prefetch((const char*)&data[i + 64], _MM_HINT_T0);
        }
        sum += data[i];
    }

    std::cout << "Sum: " << sum << "\n";
    delete[] data;
}
```

---

## 6. 線程池

```cpp
#include <thread>
#include <vector>
#include <queue>
#include <functional>
#include <mutex>
#include <condition_variable>

class ThreadPool {
public:
    ThreadPool(size_t num_threads) : stop_(false) {
        for (size_t i = 0; i < num_threads; ++i) {
            workers_.emplace_back([this]() {
                while (true) {
                    std::function<void()> task;

                    {
                        std::unique_lock<std::mutex> lock(mutex_);
                        cv_.wait(lock, [this]() {
                            return stop_ || !tasks_.empty();
                        });

                        if (stop_ && tasks_.empty()) {
                            return;
                        }

                        task = std::move(tasks_.front());
                        tasks_.pop();
                    }

                    task();
                }
            });
        }
    }

    ~ThreadPool() {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            stop_ = true;
        }
        cv_.notify_all();

        for (auto& worker : workers_) {
            worker.join();
        }
    }

    template<typename F>
    void enqueue(F&& f) {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            tasks_.emplace(std::forward<F>(f));
        }
        cv_.notify_one();
    }

private:
    std::vector<std::thread> workers_;
    std::queue<std::function<void()>> tasks_;
    std::mutex mutex_;
    std::condition_variable cv_;
    bool stop_;
};

void thread_pool_example() {
    ThreadPool pool(4);

    for (int i = 0; i < 10; ++i) {
        pool.enqueue([i]() {
            std::cout << "Task " << i << " running on thread "
                      << std::this_thread::get_id() << "\n";
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
        });
    }

    std::this_thread::sleep_for(std::chrono::seconds(2));
}
```

---

---

## 7. 性能測量與分析

### 7.1 高精度計時

```cpp
#include <chrono>

class Timer {
public:
    Timer() : start_(std::chrono::high_resolution_clock::now()) {}

    void reset() {
        start_ = std::chrono::high_resolution_clock::now();
    }

    double elapsed_ns() const {
        auto end = std::chrono::high_resolution_clock::now();
        return std::chrono::duration<double, std::nano>(end - start_).count();
    }

    double elapsed_us() const {
        return elapsed_ns() / 1000.0;
    }

    double elapsed_ms() const {
        return elapsed_us() / 1000.0;
    }

private:
    std::chrono::high_resolution_clock::time_point start_;
};

void timing_example() {
    Timer timer;

    // 執行操作
    std::this_thread::sleep_for(std::chrono::milliseconds(100));

    std::cout << "Elapsed: " << timer.elapsed_ms() << " ms\n";
}
```

### 7.2 延遲測量

```cpp
#include <vector>
#include <algorithm>

class LatencyMeasurement {
public:
    void record(double latency_ns) {
        latencies_.push_back(latency_ns);
    }

    void print_statistics() {
        if (latencies_.empty()) return;

        std::sort(latencies_.begin(), latencies_.end());

        double sum = std::accumulate(latencies_.begin(), latencies_.end(), 0.0);
        double avg = sum / latencies_.size();

        size_t p50_idx = latencies_.size() * 0.50;
        size_t p99_idx = latencies_.size() * 0.99;
        size_t p999_idx = latencies_.size() * 0.999;

        std::cout << "Latency Statistics (ns):\n";
        std::cout << "  Min:  " << latencies_.front() << "\n";
        std::cout << "  Avg:  " << avg << "\n";
        std::cout << "  P50:  " << latencies_[p50_idx] << "\n";
        std::cout << "  P99:  " << latencies_[p99_idx] << "\n";
        std::cout << "  P999: " << latencies_[p999_idx] << "\n";
        std::cout << "  Max:  " << latencies_.back() << "\n";
    }

private:
    std::vector<double> latencies_;
};
```

---

## 8. 異步編程與協程

### 8.1 C++ 標準異步工具

#### std::async 與 std::future

**核心概念:**

`std::async` 提供了簡單的異步任務執行機制:

- **自動線程管理**: 無需手動創建線程
- **結果獲取**: 通過 `std::future` 獲取異步結果
- **異常傳播**: 異常會自動傳播到調用者

```cpp
#include <future>
#include <iostream>
#include <chrono>

// 異步計算函數
int expensive_computation(int x) {
    std::this_thread::sleep_for(std::chrono::seconds(1));
    return x * x;
}

void async_basic_example() {
    // 啟動異步任務
    std::future<int> result = std::async(std::launch::async,
                                         expensive_computation, 10);

    std::cout << "Doing other work while computation runs...\n";

    // 獲取結果 (阻塞直到完成)
    int value = result.get();
    std::cout << "Result: " << value << "\n";  // 100
}

// 啟動策略
void launch_policy_example() {
    // std::launch::async - 立即在新線程中執行
    auto f1 = std::async(std::launch::async, []() {
        return 42;
    });

    // std::launch::deferred - 延遲執行 (調用 get() 時才執行)
    auto f2 = std::async(std::launch::deferred, []() {
        return 100;
    });

    // 默認策略 (實現定義,可能是 async 或 deferred)
    auto f3 = std::async([]() {
        return 200;
    });

    std::cout << f1.get() << "\n";  // 42
    std::cout << f2.get() << "\n";  // 100 (此時才執行)
    std::cout << f3.get() << "\n";  // 200
}
```

#### std::promise 與 std::future

**核心概念:**

`std::promise` 允許在一個線程中設置值,在另一個線程中獲取:

- **手動控制**: 完全控制何時設置結果
- **一次性**: 每個 promise 只能設置一次值
- **異常傳播**: 可以傳播異常

```cpp
#include <future>
#include <thread>

void promise_example() {
    std::promise<int> promise;
    std::future<int> future = promise.get_future();

    // 生產者線程
    std::thread producer([&promise]() {
        std::this_thread::sleep_for(std::chrono::seconds(1));
        promise.set_value(42);  // 設置結果
    });

    // 消費者線程 (主線程)
    std::cout << "Waiting for result...\n";
    int result = future.get();  // 阻塞等待
    std::cout << "Got result: " << result << "\n";

    producer.join();
}

// 異常傳播
void promise_exception_example() {
    std::promise<int> promise;
    std::future<int> future = promise.get_future();

    std::thread t([&promise]() {
        try {
            throw std::runtime_error("Something went wrong");
        } catch (...) {
            promise.set_exception(std::current_exception());
        }
    });

    try {
        future.get();  // 重新拋出異常
    } catch (const std::exception& e) {
        std::cout << "Caught: " << e.what() << "\n";
    }

    t.join();
}
```

**HFT 適用性分析:**

| 特性   | std::async | 手動線程 | 評價          |
| ------ | ---------- | -------- | ------------- |
| 延遲   | ~1-10μs    | ~100ns   | ❌ 不適合 HFT |
| 開銷   | 線程創建   | 可控     | ❌ 開銷大     |
| 靈活性 | 低         | 高       | ❌ 控制有限   |

**結論**: `std::async` 不適合 HFT 關鍵路徑,但可用於:

- 非關鍵路徑的後台任務
- 初始化階段的並行處理
- 日誌、監控等輔助功能

---

### 8.2 C++20 Coroutines (協程)

**核心概念:**

協程 (Coroutines) 是 C++20 引入的革命性特性:

- **可暫停函數**: 函數可以暫停並稍後恢復
- **無棧協程**: 狀態保存在堆上,開銷小
- **語法糖**: `co_await`, `co_yield`, `co_return`
- **零開銷抽象**: 編譯器優化後性能極佳

#### 協程關鍵字

```cpp
// co_return - 返回值並結束協程
Task<int> simple_coroutine() {
    co_return 42;
}

// co_yield - 產生值並暫停 (Generator)
Generator<int> range(int start, int end) {
    for (int i = start; i < end; ++i) {
        co_yield i;  // 產生值並暫停
    }
}

// co_await - 等待異步操作完成
Task<int> async_operation() {
    int result = co_await some_async_task();
    co_return result;
}
```

#### Generator 實現 (同步協程)

```cpp
#include <coroutine>
#include <iostream>
#include <exception>

// Generator 協程類型
template<typename T>
class Generator {
public:
    struct promise_type {
        T current_value;
        std::exception_ptr exception;

        Generator get_return_object() {
            return Generator{std::coroutine_handle<promise_type>::from_promise(*this)};
        }

        std::suspend_always initial_suspend() { return {}; }
        std::suspend_always final_suspend() noexcept { return {}; }

        std::suspend_always yield_value(T value) {
            current_value = value;
            return {};
        }

        void return_void() {}

        void unhandled_exception() {
            exception = std::current_exception();
        }
    };

    struct iterator {
        std::coroutine_handle<promise_type> handle;

        iterator& operator++() {
            handle.resume();
            return *this;
        }

        T operator*() const {
            return handle.promise().current_value;
        }

        bool operator!=(const iterator& other) const {
            return !handle.done();
        }
    };

    iterator begin() {
        handle.resume();
        return {handle};
    }

    iterator end() { return {nullptr}; }

    ~Generator() {
        if (handle) handle.destroy();
    }

private:
    explicit Generator(std::coroutine_handle<promise_type> h) : handle(h) {}
    std::coroutine_handle<promise_type> handle;
};

// 使用 Generator
Generator<int> fibonacci(int n) {
    int a = 0, b = 1;
    for (int i = 0; i < n; ++i) {
        co_yield a;
        int next = a + b;
        a = b;
        b = next;
    }
}

void generator_example() {
    for (int value : fibonacci(10)) {
        std::cout << value << " ";  // 0 1 1 2 3 5 8 13 21 34
    }
    std::cout << "\n";
}
```

#### Task 實現 (異步協程)

```cpp
#include <coroutine>
#include <optional>

// 簡化的 Task 類型
template<typename T>
class Task {
public:
    struct promise_type {
        std::optional<T> result;

        Task get_return_object() {
            return Task{std::coroutine_handle<promise_type>::from_promise(*this)};
        }

        std::suspend_never initial_suspend() { return {}; }
        std::suspend_always final_suspend() noexcept { return {}; }

        void return_value(T value) {
            result = value;
        }

        void unhandled_exception() {
            std::terminate();
        }
    };

    T get() {
        if (!handle.done()) {
            handle.resume();
        }
        return *handle.promise().result;
    }

    ~Task() {
        if (handle) handle.destroy();
    }

private:
    explicit Task(std::coroutine_handle<promise_type> h) : handle(h) {}
    std::coroutine_handle<promise_type> handle;
};

// 異步任務示例
Task<int> async_compute(int x) {
    // 模擬異步操作
    co_return x * x;
}

void task_example() {
    Task<int> task = async_compute(10);
    int result = task.get();
    std::cout << "Result: " << result << "\n";  // 100
}
```

**協程優勢:**

1. **代碼清晰**: 避免回調地獄

   ```cpp
   // ❌ 回調地獄
   async_read(socket, [](auto data1) {
       async_process(data1, [](auto data2) {
           async_write(socket, data2, [](auto result) {
               // ...
           });
       });
   });

   // ✅ 協程 (清晰易讀)
   Task<void> handle_request() {
       auto data1 = co_await async_read(socket);
       auto data2 = co_await async_process(data1);
       co_await async_write(socket, data2);
   }
   ```

2. **性能優秀**: 零開銷抽象

   - 狀態機編譯優化
   - 無額外堆分配 (編譯器優化)
   - 無上下文切換

3. **組合性強**: 易於組合多個異步操作

---

### 8.3 異步編程模式

#### Reactor 模式 (epoll)

**特點:**

- **事件驅動**: 等待事件發生
- **回調處理**: 事件發生時調用回調
- **單線程**: 通常在單線程中處理所有事件

```cpp
// Reactor 模式偽代碼
class Reactor {
public:
    void register_handler(int fd, EventType type, Callback callback) {
        handlers_[fd] = {type, callback};
    }

    void run() {
        while (running_) {
            // 等待事件
            auto events = epoll_wait(epoll_fd_, ...);

            // 處理事件
            for (auto& event : events) {
                auto& handler = handlers_[event.fd];
                handler.callback(event);  // 回調
            }
        }
    }
};
```

#### Proactor 模式 (io_uring)

**特點:**

- **異步 I/O**: 操作立即返回
- **完成通知**: 操作完成後通知
- **批量處理**: 可批量提交和獲取

```cpp
// Proactor 模式偽代碼
class Proactor {
public:
    void async_read(int fd, Buffer buffer, Callback callback) {
        // 提交異步讀取請求
        submit_read_request(fd, buffer);
        callbacks_[request_id] = callback;
    }

    void run() {
        while (running_) {
            // 獲取完成的操作
            auto completions = get_completions();

            // 處理完成事件
            for (auto& completion : completions) {
                auto& callback = callbacks_[completion.id];
                callback(completion.result);  // 回調
            }
        }
    }
};
```

**模式對比:**

| 特性     | Reactor (epoll) | Proactor (io_uring) |
| -------- | --------------- | ------------------- |
| 延遲     | ~1-5μs          | ~0.5-2μs            |
| 系統調用 | 每次事件        | 批量處理            |
| 複雜度   | 中等            | 高                  |
| HFT 適用 | ✅ 適用         | ✅ 更優             |

---

### 8.4 HFT 異步架構

#### 異步市場數據接收

```cpp
#include <coroutine>
#include <vector>

// 市場數據事件
struct MarketDataEvent {
    uint64_t timestamp;
    uint32_t symbol_id;
    double price;
    uint32_t quantity;
};

// 異步市場數據接收器
class AsyncMarketDataReceiver {
public:
    // 使用協程接收數據
    Task<MarketDataEvent> receive_next() {
        // 等待下一個市場數據事件
        co_return co_await wait_for_market_data();
    }

private:
    // 實際的異步等待實現 (使用 io_uring 或 epoll)
    Awaitable<MarketDataEvent> wait_for_market_data() {
        // ... io_uring 實現 ...
    }
};

// 策略引擎使用協程處理市場數據
Task<void> strategy_engine() {
    AsyncMarketDataReceiver receiver;

    while (true) {
        // 異步接收市場數據
        auto event = co_await receiver.receive_next();

        // 處理市場數據
        process_market_data(event);

        // 如果需要發送訂單
        if (should_send_order(event)) {
            co_await send_order_async(create_order(event));
        }
    }
}
```

#### 異步訂單發送

```cpp
// 異步訂單發送器
class AsyncOrderSender {
public:
    Task<bool> send_order(const Order& order) {
        // 序列化訂單
        auto buffer = serialize_order(order);

        // 異步發送 (使用 io_uring)
        co_return co_await async_write(socket_fd_, buffer);
    }

private:
    int socket_fd_;

    Awaitable<bool> async_write(int fd, const Buffer& buffer) {
        // ... io_uring 異步寫入實現 ...
    }
};
```

#### 完整的異步 HFT 流程

```cpp
// 完整的異步交易流程
Task<void> hft_trading_loop() {
    AsyncMarketDataReceiver md_receiver;
    AsyncOrderSender order_sender;

    while (true) {
        // 1. 異步接收市場數據
        auto md_event = co_await md_receiver.receive_next();

        auto start_time = rdtsc();  // 記錄開始時間

        // 2. 策略計算 (同步,極快)
        auto signal = strategy.calculate(md_event);

        // 3. 如果有交易信號
        if (signal.should_trade) {
            // 4. 創建訂單
            auto order = create_order(signal);

            // 5. 異步發送訂單
            bool success = co_await order_sender.send_order(order);

            // 6. 記錄延遲
            auto end_time = rdtsc();
            auto latency_ns = (end_time - start_time) * ns_per_cycle;
            latency_tracker.record(latency_ns);

            if (!success) {
                log_error("Order send failed");
            }
        }
    }
}
```

---

### 8.5 協程 vs 其他方案

**性能對比:**

| 方案            | 延遲         | 內存開銷     | 代碼複雜度    | HFT 推薦   |
| --------------- | ------------ | ------------ | ------------- | ---------- |
| 回調            | 極低 (~50ns) | 極小         | 高 (回調地獄) | ⭐⭐⭐     |
| 線程            | 高 (~1μs)    | 大 (MB/線程) | 中等          | ⭐         |
| std::async      | 高 (~10μs)   | 大           | 低            | ⭐         |
| 協程 (C++20)    | 低 (~100ns)  | 小 (KB)      | 低            | ⭐⭐⭐⭐⭐ |
| SPSC + 專用線程 | 極低 (~10ns) | 中等         | 中等          | ⭐⭐⭐⭐⭐ |

**最佳實踐:**

1. **關鍵路徑**: 使用 SPSC 隊列 + 專用線程

   - 市場數據接收 -> 策略引擎
   - 策略引擎 -> 訂單發送

2. **非關鍵路徑**: 使用協程

   - 風險檢查
   - 日誌記錄
   - 監控上報

3. **後台任務**: 使用 std::async 或線程池
   - 數據持久化
   - 統計計算
   - 系統監控

---

### 8.6 實戰建議

#### 何時使用協程

✅ **適合使用協程:**

- I/O 密集型操作 (網路、文件)
- 需要等待多個異步操作
- 代碼可讀性重要
- 非極端延遲敏感 (< 1μs)

❌ **不適合使用協程:**

- 極端延遲敏感 (< 100ns)
- CPU 密集型計算
- 簡單的同步操作

#### 協程最佳實踐

```cpp
// ✅ 好的協程使用
Task<void> good_coroutine_usage() {
    // 1. 異步 I/O 操作
    auto data = co_await async_read(socket);

    // 2. 同步處理 (快速)
    auto processed = process_data(data);

    // 3. 異步寫入
    co_await async_write(socket, processed);
}

// ❌ 不好的協程使用
Task<int> bad_coroutine_usage() {
    // 不要在協程中做 CPU 密集型計算
    int result = 0;
    for (int i = 0; i < 1000000; ++i) {
        result += expensive_computation(i);  // 阻塞協程!
    }
    co_return result;
}
```

#### 錯誤處理

```cpp
// 協程中的異常處理
Task<void> coroutine_with_error_handling() {
    try {
        auto data = co_await async_read(socket);
        co_await async_process(data);
    } catch (const std::exception& e) {
        log_error("Coroutine error: ", e.what());
        // 清理資源
        co_await cleanup();
    }
}
```

---

### 8.7 總結

**異步編程工具對比:**

| 工具                  | 適用場景   | HFT 推薦度 |
| --------------------- | ---------- | ---------- |
| std::async            | 後台任務   | ⭐⭐       |
| std::promise/future   | 線程間通信 | ⭐⭐       |
| C++20 協程            | 異步 I/O   | ⭐⭐⭐⭐   |
| SPSC 隊列             | 關鍵路徑   | ⭐⭐⭐⭐⭐ |
| 回調 + epoll/io_uring | 極致性能   | ⭐⭐⭐⭐⭐ |

**關鍵要點:**

1. **協程是未來**: C++20 協程提供了優雅的異步編程方式
2. **性能可接受**: 對於大多數場景,協程性能足夠好
3. **關鍵路徑例外**: 極端延遲敏感的路徑仍需手動優化
4. **組合使用**: 協程 + SPSC 隊列 + 專用線程 = 最佳架構

---

## 總結

本章涵蓋了並發與性能優化的核心技術:

1. **多線程**: std::thread、thread_local
2. **同步**: mutex、condition_variable
3. **原子操作**: std::atomic、CAS、內存序
4. **無鎖編程**: 無鎖棧、SPSC 隊列
5. **緩存優化**: False Sharing、預取
6. **線程池**: 任務調度
7. **性能測量**: 高精度計時、延遲統計
8. **異步編程**: std::async、C++20 協程、異步模式

**HFT 關鍵要點:**

- ✅ 使用 SPSC 隊列進行線程間通信
- ✅ 避免 False Sharing (alignas(64))
- ✅ 綁定關鍵線程到獨立 CPU
- ✅ 使用實時調度策略 (SCHED_FIFO)
- ✅ 選擇合適的內存序 (relaxed/acquire/release)
- ✅ 測量 P99/P999 延遲而非平均值
- ✅ 關鍵路徑使用專用線程,非關鍵路徑使用協程
- ✅ 優先使用 io_uring 而非 epoll

**性能對比:**

| 技術             | 延遲   | 吞吐量 | 複雜度 | HFT 推薦   |
| ---------------- | ------ | ------ | ------ | ---------- |
| Mutex            | ~25ns  | 中等   | 低     | ⭐⭐       |
| Spinlock         | ~10ns  | 高     | 低     | ⭐⭐⭐     |
| Atomic (seq_cst) | ~5ns   | 高     | 中等   | ⭐⭐⭐⭐   |
| Atomic (relaxed) | ~2ns   | 極高   | 高     | ⭐⭐⭐⭐⭐ |
| SPSC Queue       | ~10ns  | 極高   | 中等   | ⭐⭐⭐⭐⭐ |
| C++20 協程       | ~100ns | 高     | 低     | ⭐⭐⭐⭐   |
| 回調 + io_uring  | ~50ns  | 極高   | 高     | ⭐⭐⭐⭐⭐ |

**下一步:**

- 學習網路編程 (epoll、io_uring)
- 掌握編譯優化技術
- 深入系統調優 (內存、CPU)
- 實踐協程在 HFT 系統中的應用

## 參考資料 (References)

1. [C++ Concurrency in Action, 2nd Edition](https://www.manning.com/books/c-plus-plus-concurrency-in-action-second-edition) - Anthony Williams
2. [The Art of Multiprocessor Programming](https://www.elsevier.com/books/the-art-of-multiprocessor-programming/herlihy/978-0-12-415950-1) - Maurice Herlihy
3. [C++ Memory Model](https://en.cppreference.com/w/cpp/atomic/memory_order)
4. [Lock-Free Programming](https://preshing.com/20120612/an-introduction-to-lock-free-programming/)
5. [False Sharing](https://mechanical-sympathy.blogspot.com/2011/07/false-sharing.html)
6. [C++20 Coroutines](https://en.cppreference.com/w/cpp/language/coroutines)
7. [Understanding C++20 Coroutines](https://lewissbaker.github.io/)
8. [io_uring Introduction](https://kernel.dk/io_uring.pdf)
