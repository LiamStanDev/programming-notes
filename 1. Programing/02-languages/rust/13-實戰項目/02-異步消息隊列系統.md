# 異步消息隊列系統

## 1. 項目概述

### 1.1 功能需求

```rust
// 核心功能
/*
1. 消息管理
   - 生產者/消費者模式
   - 消息持久化
   - 消息優先級
   - 延遲消息

2. 隊列特性
   - 多隊列支持
   - 消息分區
   - 消費者組
   - 消息確認機制

3. 可靠性
   - 消息持久化到磁盤
   - 主從複製
   - 故障恢復
   - 消息重試

4. 性能
   - 高吞吐量 (100k+ msg/s)
   - 低延遲 (< 1ms)
   - 批量操作
   - 零拷貝
*/
```

### 1.2 技術架構

```toml
# Cargo.toml
[package]
name = "async-message-queue"
version = "0.1.0"
edition = "2021"

[dependencies]
# 異步運行時
tokio = { version = "1.35", features = ["full"] }
futures = "0.3"

# 網絡
tokio-util = { version = "0.7", features = ["codec"] }
bytes = "1.5"

# 序列化
serde = { version = "1.0", features = ["derive"] }
bincode = "1.3"
rmp-serde = "1.1" # MessagePack

# 持久化
sled = "0.34" # 嵌入式數據庫
tokio-uring = "0.4" # io_uring for Linux

# 並發
crossbeam = "0.8"
flume = "0.11"
parking_lot = "0.12"

# 時間
chrono = "0.4"

# 日誌
tracing = "0.1"
tracing-subscriber = "0.3"

# 錯誤處理
anyhow = "1.0"
thiserror = "1.0"

# 監控
prometheus = "0.13"

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
```

## 2. 核心數據結構

### 2.1 消息定義

```rust
// src/message.rs
use bytes::Bytes;
use serde::{Deserialize, Serialize};
use std::time::{Duration, SystemTime};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Message {
    pub id: MessageId,
    pub topic: String,
    pub key: Option<String>,
    pub payload: Bytes,
    pub headers: MessageHeaders,
    pub metadata: MessageMetadata,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct MessageId {
    pub timestamp: u64,  // Unix timestamp in microseconds
    pub sequence: u64,   // Sequence number
    pub partition: u32,  // Partition ID
}

impl MessageId {
    pub fn new(partition: u32, sequence: u64) -> Self {
        let timestamp = SystemTime::now()
            .duration_since(SystemTime::UNIX_EPOCH)
            .unwrap()
            .as_micros() as u64;
        
        Self {
            timestamp,
            sequence,
            partition,
        }
    }
    
    pub fn as_bytes(&self) -> [u8; 20] {
        let mut bytes = [0u8; 20];
        bytes[0..8].copy_from_slice(&self.timestamp.to_be_bytes());
        bytes[8..16].copy_from_slice(&self.sequence.to_be_bytes());
        bytes[16..20].copy_from_slice(&self.partition.to_be_bytes());
        bytes
    }
    
    pub fn from_bytes(bytes: &[u8]) -> Self {
        Self {
            timestamp: u64::from_be_bytes(bytes[0..8].try_into().unwrap()),
            sequence: u64::from_be_bytes(bytes[8..16].try_into().unwrap()),
            partition: u32::from_be_bytes(bytes[16..20].try_into().unwrap()),
        }
    }
}

#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct MessageHeaders {
    pub content_type: Option<String>,
    pub correlation_id: Option<String>,
    pub reply_to: Option<String>,
    pub custom: std::collections::HashMap<String, String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MessageMetadata {
    pub priority: Priority,
    pub ttl: Option<Duration>,
    pub created_at: SystemTime,
    pub delivery_count: u32,
    pub delay_until: Option<SystemTime>,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
pub enum Priority {
    Low = 0,
    Normal = 1,
    High = 2,
    Critical = 3,
}

impl Default for MessageMetadata {
    fn default() -> Self {
        Self {
            priority: Priority::Normal,
            ttl: None,
            created_at: SystemTime::now(),
            delivery_count: 0,
            delay_until: None,
        }
    }
}

impl Message {
    pub fn new(topic: impl Into<String>, payload: impl Into<Bytes>) -> Self {
        Self {
            id: MessageId::new(0, 0), // Will be assigned by queue
            topic: topic.into(),
            key: None,
            payload: payload.into(),
            headers: MessageHeaders::default(),
            metadata: MessageMetadata::default(),
        }
    }
    
    pub fn with_key(mut self, key: impl Into<String>) -> Self {
        self.key = Some(key.into());
        self
    }
    
    pub fn with_priority(mut self, priority: Priority) -> Self {
        self.metadata.priority = priority;
        self
    }
    
    pub fn with_delay(mut self, delay: Duration) -> Self {
        self.metadata.delay_until = Some(SystemTime::now() + delay);
        self
    }
    
    pub fn is_expired(&self) -> bool {
        if let Some(ttl) = self.metadata.ttl {
            if let Ok(elapsed) = self.metadata.created_at.elapsed() {
                return elapsed > ttl;
            }
        }
        false
    }
    
    pub fn is_ready(&self) -> bool {
        if let Some(delay_until) = self.metadata.delay_until {
            SystemTime::now() >= delay_until
        } else {
            true
        }
    }
}
```

### 2.2 隊列實現

```rust
// src/queue.rs
use crate::message::{Message, MessageId, Priority};
use std::collections::{BTreeMap, VecDeque};
use std::sync::Arc;
use parking_lot::RwLock;
use tokio::sync::Notify;

pub struct Queue {
    name: String,
    partitions: Vec<Partition>,
    config: QueueConfig,
}

#[derive(Debug, Clone)]
pub struct QueueConfig {
    pub num_partitions: usize,
    pub max_size_bytes: usize,
    pub retention: Option<std::time::Duration>,
    pub enable_persistence: bool,
}

impl Default for QueueConfig {
    fn default() -> Self {
        Self {
            num_partitions: 4,
            max_size_bytes: 1024 * 1024 * 1024, // 1 GB
            retention: None,
            enable_persistence: true,
        }
    }
}

pub struct Partition {
    id: u32,
    messages: Arc<RwLock<PartitionState>>,
    notify: Arc<Notify>,
}

struct PartitionState {
    // 按優先級組織的消息隊列
    priority_queues: BTreeMap<Priority, VecDeque<Message>>,
    // 延遲消息，按預定時間排序
    delayed_messages: BTreeMap<std::time::SystemTime, Vec<Message>>,
    // 序列號計數器
    next_sequence: u64,
    // 當前大小
    size_bytes: usize,
}

impl Partition {
    fn new(id: u32) -> Self {
        Self {
            id,
            messages: Arc::new(RwLock::new(PartitionState {
                priority_queues: BTreeMap::new(),
                delayed_messages: BTreeMap::new(),
                next_sequence: 0,
                size_bytes: 0,
            })),
            notify: Arc::new(Notify::new()),
        }
    }
    
    pub fn push(&self, mut message: Message) -> Result<MessageId, QueueError> {
        let mut state = self.messages.write();
        
        // 分配消息 ID
        message.id = MessageId::new(self.id, state.next_sequence);
        state.next_sequence += 1;
        
        let msg_size = message.payload.len();
        state.size_bytes += msg_size;
        
        // 處理延遲消息
        if let Some(delay_until) = message.metadata.delay_until {
            state.delayed_messages
                .entry(delay_until)
                .or_insert_with(Vec::new)
                .push(message.clone());
        } else {
            // 加入優先級隊列
            let priority = message.metadata.priority;
            state.priority_queues
                .entry(priority)
                .or_insert_with(VecDeque::new)
                .push_back(message.clone());
        }
        
        // 通知等待的消費者
        self.notify.notify_one();
        
        Ok(message.id)
    }
    
    pub fn pop(&self) -> Option<Message> {
        let mut state = self.messages.write();
        
        // 首先處理延遲消息
        self.move_ready_delayed_messages(&mut state);
        
        // 按優先級從高到低取消息
        for priority in [Priority::Critical, Priority::High, Priority::Normal, Priority::Low] {
            if let Some(queue) = state.priority_queues.get_mut(&priority) {
                if let Some(message) = queue.pop_front() {
                    state.size_bytes = state.size_bytes.saturating_sub(message.payload.len());
                    return Some(message);
                }
            }
        }
        
        None
    }
    
    pub async fn pop_async(&self) -> Message {
        loop {
            if let Some(msg) = self.pop() {
                return msg;
            }
            
            // 等待新消息
            self.notify.notified().await;
        }
    }
    
    fn move_ready_delayed_messages(&self, state: &mut PartitionState) {
        let now = std::time::SystemTime::now();
        let ready_times: Vec<_> = state.delayed_messages
            .range(..=now)
            .map(|(time, _)| *time)
            .collect();
        
        for time in ready_times {
            if let Some(messages) = state.delayed_messages.remove(&time) {
                for mut message in messages {
                    message.metadata.delay_until = None;
                    let priority = message.metadata.priority;
                    state.priority_queues
                        .entry(priority)
                        .or_insert_with(VecDeque::new)
                        .push_back(message);
                }
            }
        }
    }
    
    pub fn len(&self) -> usize {
        let state = self.messages.read();
        state.priority_queues.values().map(|q| q.len()).sum::<usize>()
            + state.delayed_messages.values().map(|v| v.len()).sum::<usize>()
    }
    
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
}

#[derive(Debug, thiserror::Error)]
pub enum QueueError {
    #[error("Queue is full")]
    Full,
    #[error("Message too large")]
    MessageTooLarge,
    #[error("Persistence error: {0}")]
    Persistence(String),
}

impl Queue {
    pub fn new(name: impl Into<String>, config: QueueConfig) -> Self {
        let partitions = (0..config.num_partitions)
            .map(|id| Partition::new(id as u32))
            .collect();
        
        Self {
            name: name.into(),
            partitions,
            config,
        }
    }
    
    pub fn push(&self, message: Message) -> Result<MessageId, QueueError> {
        let partition_id = self.select_partition(&message);
        self.partitions[partition_id].push(message)
    }
    
    pub fn pop(&self, partition_id: usize) -> Option<Message> {
        self.partitions.get(partition_id)?.pop()
    }
    
    pub async fn pop_async(&self, partition_id: usize) -> Option<Message> {
        self.partitions.get(partition_id)?.pop_async().await.into()
    }
    
    fn select_partition(&self, message: &Message) -> usize {
        if let Some(ref key) = message.key {
            // 基於 key 的哈希分區
            use std::collections::hash_map::DefaultHasher;
            use std::hash::{Hash, Hasher};
            
            let mut hasher = DefaultHasher::new();
            key.hash(&mut hasher);
            (hasher.finish() as usize) % self.config.num_partitions
        } else {
            // 輪詢分區
            use std::sync::atomic::{AtomicUsize, Ordering};
            static COUNTER: AtomicUsize = AtomicUsize::new(0);
            COUNTER.fetch_add(1, Ordering::Relaxed) % self.config.num_partitions
        }
    }
    
    pub fn total_len(&self) -> usize {
        self.partitions.iter().map(|p| p.len()).sum()
    }
}
```

### 2.3 持久化層

```rust
// src/storage.rs
use crate::message::{Message, MessageId};
use sled::{Db, IVec};
use std::path::Path;
use anyhow::Result;

pub struct StorageEngine {
    db: Db,
}

impl StorageEngine {
    pub fn open(path: impl AsRef<Path>) -> Result<Self> {
        let db = sled::open(path)?;
        Ok(Self { db })
    }
    
    pub fn write_message(&self, topic: &str, message: &Message) -> Result<()> {
        let tree = self.db.open_tree(topic)?;
        let key = message.id.as_bytes();
        let value = bincode::serialize(message)?;
        tree.insert(key, value)?;
        Ok(())
    }
    
    pub fn read_message(&self, topic: &str, id: &MessageId) -> Result<Option<Message>> {
        let tree = self.db.open_tree(topic)?;
        let key = id.as_bytes();
        
        if let Some(value) = tree.get(key)? {
            let message: Message = bincode::deserialize(&value)?;
            Ok(Some(message))
        } else {
            Ok(None)
        }
    }
    
    pub fn delete_message(&self, topic: &str, id: &MessageId) -> Result<()> {
        let tree = self.db.open_tree(topic)?;
        let key = id.as_bytes();
        tree.remove(key)?;
        Ok(())
    }
    
    pub fn scan_range(
        &self,
        topic: &str,
        start: &MessageId,
        end: &MessageId,
    ) -> Result<Vec<Message>> {
        let tree = self.db.open_tree(topic)?;
        let start_key = start.as_bytes();
        let end_key = end.as_bytes();
        
        let mut messages = Vec::new();
        for item in tree.range(start_key..=end_key) {
            let (_, value) = item?;
            let message: Message = bincode::deserialize(&value)?;
            messages.push(message);
        }
        
        Ok(messages)
    }
    
    pub fn flush(&self) -> Result<usize> {
        Ok(self.db.flush()?)
    }
}

// 寫前日誌 (WAL) 實現
pub struct WriteAheadLog {
    file: tokio::fs::File,
    offset: u64,
}

impl WriteAheadLog {
    pub async fn open(path: impl AsRef<Path>) -> Result<Self> {
        use tokio::fs::OpenOptions;
        
        let file = OpenOptions::new()
            .create(true)
            .append(true)
            .open(path)
            .await?;
        
        let metadata = file.metadata().await?;
        
        Ok(Self {
            file,
            offset: metadata.len(),
        })
    }
    
    pub async fn append(&mut self, message: &Message) -> Result<u64> {
        use tokio::io::AsyncWriteExt;
        
        let data = bincode::serialize(message)?;
        let len = data.len() as u32;
        
        // 寫入長度前綴
        self.file.write_all(&len.to_le_bytes()).await?;
        // 寫入數據
        self.file.write_all(&data).await?;
        
        let offset = self.offset;
        self.offset += 4 + len as u64;
        
        Ok(offset)
    }
    
    pub async fn sync(&mut self) -> Result<()> {
        use tokio::io::AsyncWriteExt;
        self.file.flush().await?;
        Ok(())
    }
}
```

## 3. 生產者與消費者

### 3.1 生產者實現

```rust
// src/producer.rs
use crate::message::Message;
use crate::queue::{Queue, QueueError};
use std::sync::Arc;
use tokio::sync::Semaphore;

pub struct Producer {
    queue: Arc<Queue>,
    semaphore: Arc<Semaphore>,
    config: ProducerConfig,
}

#[derive(Debug, Clone)]
pub struct ProducerConfig {
    pub max_batch_size: usize,
    pub batch_timeout_ms: u64,
    pub max_in_flight: usize,
}

impl Default for ProducerConfig {
    fn default() -> Self {
        Self {
            max_batch_size: 100,
            batch_timeout_ms: 10,
            max_in_flight: 1000,
        }
    }
}

impl Producer {
    pub fn new(queue: Arc<Queue>, config: ProducerConfig) -> Self {
        let semaphore = Arc::new(Semaphore::new(config.max_in_flight));
        
        Self {
            queue,
            semaphore,
            config,
        }
    }
    
    pub async fn send(&self, message: Message) -> Result<(), QueueError> {
        // 限制並發數
        let _permit = self.semaphore.acquire().await.unwrap();
        
        self.queue.push(message)?;
        Ok(())
    }
    
    pub async fn send_batch(&self, messages: Vec<Message>) -> Result<Vec<Result<(), QueueError>>, ()> {
        let mut results = Vec::with_capacity(messages.len());
        
        for message in messages {
            let result = self.send(message).await;
            results.push(result);
        }
        
        Ok(results)
    }
}

// 批量發送優化
pub struct BatchProducer {
    producer: Producer,
    buffer: Arc<parking_lot::Mutex<Vec<Message>>>,
    config: ProducerConfig,
}

impl BatchProducer {
    pub fn new(queue: Arc<Queue>, config: ProducerConfig) -> Self {
        let producer = Producer::new(queue, config.clone());
        let buffer = Arc::new(parking_lot::Mutex::new(Vec::new()));
        
        // 啟動定時刷新任務
        let buffer_clone = buffer.clone();
        let producer_clone = producer.clone();
        let timeout = std::time::Duration::from_millis(config.batch_timeout_ms);
        
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(timeout);
            loop {
                interval.tick().await;
                Self::flush_buffer(&buffer_clone, &producer_clone).await;
            }
        });
        
        Self {
            producer,
            buffer,
            config,
        }
    }
    
    pub async fn send(&self, message: Message) {
        let should_flush = {
            let mut buffer = self.buffer.lock();
            buffer.push(message);
            buffer.len() >= self.config.max_batch_size
        };
        
        if should_flush {
            self.flush().await;
        }
    }
    
    pub async fn flush(&self) {
        Self::flush_buffer(&self.buffer, &self.producer).await;
    }
    
    async fn flush_buffer(
        buffer: &parking_lot::Mutex<Vec<Message>>,
        producer: &Producer,
    ) {
        let messages = {
            let mut buf = buffer.lock();
            std::mem::take(&mut *buf)
        };
        
        if !messages.is_empty() {
            let _ = producer.send_batch(messages).await;
        }
    }
}
```

### 3.2 消費者實現

```rust
// src/consumer.rs
use crate::message::Message;
use crate::queue::Queue;
use std::sync::Arc;
use tokio::sync::mpsc;

pub struct Consumer {
    queue: Arc<Queue>,
    partition_id: usize,
    config: ConsumerConfig,
}

#[derive(Debug, Clone)]
pub struct ConsumerConfig {
    pub auto_commit: bool,
    pub fetch_max_wait_ms: u64,
    pub max_poll_records: usize,
}

impl Default for ConsumerConfig {
    fn default() -> Self {
        Self {
            auto_commit: true,
            fetch_max_wait_ms: 500,
            max_poll_records: 100,
        }
    }
}

impl Consumer {
    pub fn new(queue: Arc<Queue>, partition_id: usize, config: ConsumerConfig) -> Self {
        Self {
            queue,
            partition_id,
            config,
        }
    }
    
    pub async fn poll(&self) -> Option<Message> {
        self.queue.pop_async(self.partition_id).await
    }
    
    pub async fn poll_batch(&self, max_records: usize) -> Vec<Message> {
        let mut messages = Vec::new();
        
        for _ in 0..max_records {
            if let Some(msg) = self.queue.pop(self.partition_id) {
                messages.push(msg);
            } else {
                break;
            }
        }
        
        messages
    }
    
    pub fn start_consuming<F>(self, handler: F) -> ConsumerHandle
    where
        F: Fn(Message) -> Result<(), anyhow::Error> + Send + 'static,
    {
        let (shutdown_tx, mut shutdown_rx) = mpsc::channel(1);
        
        let handle = tokio::spawn(async move {
            loop {
                tokio::select! {
                    message = self.poll() => {
                        if let Err(e) = handler(message) {
                            tracing::error!("Error processing message: {}", e);
                        }
                    }
                    _ = shutdown_rx.recv() => {
                        tracing::info!("Consumer shutting down");
                        break;
                    }
                }
            }
        });
        
        ConsumerHandle {
            handle,
            shutdown_tx,
        }
    }
}

pub struct ConsumerHandle {
    handle: tokio::task::JoinHandle<()>,
    shutdown_tx: mpsc::Sender<()>,
}

impl ConsumerHandle {
    pub async fn shutdown(self) {
        let _ = self.shutdown_tx.send(()).await;
        let _ = self.handle.await;
    }
}

// 消費者組實現
pub struct ConsumerGroup {
    group_id: String,
    consumers: Vec<Consumer>,
    coordinator: Arc<GroupCoordinator>,
}

struct GroupCoordinator {
    assignments: parking_lot::RwLock<std::collections::HashMap<String, Vec<usize>>>,
}

impl ConsumerGroup {
    pub fn new(
        group_id: String,
        queue: Arc<Queue>,
        num_consumers: usize,
        config: ConsumerConfig,
    ) -> Self {
        let num_partitions = queue.config.num_partitions;
        
        // 分配分區給消費者
        let mut consumers = Vec::new();
        for i in 0..num_consumers {
            let assigned_partitions: Vec<usize> = (0..num_partitions)
                .filter(|p| p % num_consumers == i)
                .collect();
            
            for partition in assigned_partitions {
                consumers.push(Consumer::new(
                    queue.clone(),
                    partition,
                    config.clone(),
                ));
            }
        }
        
        Self {
            group_id,
            consumers,
            coordinator: Arc::new(GroupCoordinator {
                assignments: parking_lot::RwLock::new(std::collections::HashMap::new()),
            }),
        }
    }
    
    pub fn start_all<F>(self, handler: F) -> Vec<ConsumerHandle>
    where
        F: Fn(Message) -> Result<(), anyhow::Error> + Send + Clone + 'static,
    {
        self.consumers
            .into_iter()
            .map(|consumer| consumer.start_consuming(handler.clone()))
            .collect()
    }
}
```

## 4. 網絡協議與服務器

### 4.1 協議定義

```rust
// src/protocol.rs
use crate::message::Message;
use bytes::{Buf, BufMut, Bytes, BytesMut};
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Command {
    Publish { topic: String, message: Message },
    Subscribe { topic: String, partition: Option<usize> },
    Unsubscribe { topic: String },
    Ack { message_id: crate::message::MessageId },
    Ping,
    Pong,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Response {
    Ok,
    Message(Message),
    Error(String),
    Pong,
}

pub struct Codec;

impl Codec {
    const MAX_FRAME_SIZE: usize = 10 * 1024 * 1024; // 10 MB
    
    pub fn encode(command: &Command, dst: &mut BytesMut) -> Result<(), std::io::Error> {
        let data = bincode::serialize(command)
            .map_err(|e| std::io::Error::new(std::io::ErrorKind::InvalidData, e))?;
        
        if data.len() > Self::MAX_FRAME_SIZE {
            return Err(std::io::Error::new(
                std::io::ErrorKind::InvalidData,
                "Frame too large",
            ));
        }
        
        dst.put_u32(data.len() as u32);
        dst.put_slice(&data);
        Ok(())
    }
    
    pub fn decode(src: &mut BytesMut) -> Result<Option<Command>, std::io::Error> {
        if src.len() < 4 {
            return Ok(None);
        }
        
        let mut length_bytes = [0u8; 4];
        length_bytes.copy_from_slice(&src[..4]);
        let length = u32::from_be_bytes(length_bytes) as usize;
        
        if length > Self::MAX_FRAME_SIZE {
            return Err(std::io::Error::new(
                std::io::ErrorKind::InvalidData,
                "Frame too large",
            ));
        }
        
        if src.len() < 4 + length {
            return Ok(None);
        }
        
        src.advance(4);
        let data = src.split_to(length);
        
        let command = bincode::deserialize(&data)
            .map_err(|e| std::io::Error::new(std::io::ErrorKind::InvalidData, e))?;
        
        Ok(Some(command))
    }
}
```

### 4.2 服務器實現

```rust
// src/server.rs
use crate::protocol::{Codec, Command, Response};
use crate::queue::Queue;
use std::collections::HashMap;
use std::sync::Arc;
use tokio::net::{TcpListener, TcpStream};
use tokio::sync::RwLock;
use tracing::{error, info};

pub struct Server {
    queues: Arc<RwLock<HashMap<String, Arc<Queue>>>>,
    bind_addr: String,
}

impl Server {
    pub fn new(bind_addr: String) -> Self {
        Self {
            queues: Arc::new(RwLock::new(HashMap::new())),
            bind_addr,
        }
    }
    
    pub async fn run(&self) -> anyhow::Result<()> {
        let listener = TcpListener::bind(&self.bind_addr).await?;
        info!("Message queue server listening on {}", self.bind_addr);
        
        loop {
            let (socket, addr) = listener.accept().await?;
            info!("New connection from {}", addr);
            
            let queues = self.queues.clone();
            tokio::spawn(async move {
                if let Err(e) = Self::handle_connection(socket, queues).await {
                    error!("Connection error: {}", e);
                }
            });
        }
    }
    
    async fn handle_connection(
        mut socket: TcpStream,
        queues: Arc<RwLock<HashMap<String, Arc<Queue>>>>,
    ) -> anyhow::Result<()> {
        use tokio::io::{AsyncReadExt, AsyncWriteExt};
        
        let mut buffer = bytes::BytesMut::with_capacity(4096);
        
        loop {
            // 讀取數據
            let n = socket.read_buf(&mut buffer).await?;
            if n == 0 {
                break;
            }
            
            // 解碼命令
            while let Some(command) = Codec::decode(&mut buffer)? {
                let response = Self::process_command(command, &queues).await;
                
                // 編碼響應
                let mut response_buf = bytes::BytesMut::new();
                let resp_data = bincode::serialize(&response)?;
                response_buf.put_u32(resp_data.len() as u32);
                response_buf.put_slice(&resp_data);
                
                // 發送響應
                socket.write_all(&response_buf).await?;
            }
        }
        
        Ok(())
    }
    
    async fn process_command(
        command: Command,
        queues: &Arc<RwLock<HashMap<String, Arc<Queue>>>>,
    ) -> Response {
        match command {
            Command::Publish { topic, message } => {
                let queues_read = queues.read().await;
                
                if let Some(queue) = queues_read.get(&topic) {
                    match queue.push(message) {
                        Ok(_) => Response::Ok,
                        Err(e) => Response::Error(e.to_string()),
                    }
                } else {
                    drop(queues_read);
                    
                    // 創建新隊列
                    let mut queues_write = queues.write().await;
                    let queue = Arc::new(Queue::new(
                        topic.clone(),
                        crate::queue::QueueConfig::default(),
                    ));
                    queues_write.insert(topic.clone(), queue.clone());
                    
                    match queue.push(message) {
                        Ok(_) => Response::Ok,
                        Err(e) => Response::Error(e.to_string()),
                    }
                }
            }
            Command::Subscribe { topic, partition } => {
                let queues_read = queues.read().await;
                
                if let Some(queue) = queues_read.get(&topic) {
                    let partition_id = partition.unwrap_or(0);
                    if let Some(message) = queue.pop(partition_id) {
                        Response::Message(message)
                    } else {
                        Response::Ok
                    }
                } else {
                    Response::Error(format!("Topic {} not found", topic))
                }
            }
            Command::Ping => Response::Pong,
            _ => Response::Error("Not implemented".to_string()),
        }
    }
}
```

## 5. 性能優化

### 5.1 批量操作

```rust
// 批量寫入優化
impl Queue {
    pub fn push_batch(&self, messages: Vec<Message>) -> Vec<Result<MessageId, QueueError>> {
        messages
            .into_iter()
            .map(|msg| self.push(msg))
            .collect()
    }
}
```

### 5.2 零拷貝

```rust
// 使用 Bytes 避免不必要的拷貝
use bytes::Bytes;

pub struct ZeroCopyMessage {
    payload: Bytes, // 引用計數，無需拷貝
}
```

### 5.3 內存池

```rust
// src/pool.rs
use bytes::{Bytes, BytesMut};
use std::sync::Arc;

pub struct BufferPool {
    pool: crossbeam::queue::ArrayQueue<BytesMut>,
    capacity: usize,
}

impl BufferPool {
    pub fn new(size: usize, capacity: usize) -> Self {
        let pool = crossbeam::queue::ArrayQueue::new(size);
        Self { pool, capacity }
    }
    
    pub fn acquire(&self) -> BytesMut {
        self.pool
            .pop()
            .unwrap_or_else(|| BytesMut::with_capacity(self.capacity))
    }
    
    pub fn release(&self, mut buffer: BytesMut) {
        buffer.clear();
        let _ = self.pool.push(buffer);
    }
}
```

## 6. 測試

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_queue_operations() {
        let queue = Arc::new(Queue::new("test", QueueConfig::default()));
        
        let msg = Message::new("test-topic", b"Hello, World!");
        let id = queue.push(msg.clone()).unwrap();
        
        let retrieved = queue.pop(0).unwrap();
        assert_eq!(retrieved.payload, msg.payload);
    }
    
    #[tokio::test]
    async fn test_priority_queue() {
        let queue = Arc::new(Queue::new("test", QueueConfig::default()));
        
        queue.push(Message::new("topic", "normal").with_priority(Priority::Normal)).unwrap();
        queue.push(Message::new("topic", "high").with_priority(Priority::High)).unwrap();
        queue.push(Message::new("topic", "low").with_priority(Priority::Low)).unwrap();
        
        let msg1 = queue.pop(0).unwrap();
        assert_eq!(msg1.metadata.priority, Priority::High);
    }
}
```

這個異步消息隊列系統實現了完整的生產者/消費者模式、消息持久化、優先級隊列等核心功能。
