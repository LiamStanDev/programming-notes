# 異步性能優化

## 性能分析基礎

### Tokio Console

實時監控 Tokio 運行時：

```toml
# Cargo.toml
[dependencies]
tokio = { version = "1", features = ["full", "tracing"] }
console-subscriber = "0.2"
```

```rust
fn main() {
    console_subscriber::init();
    
    let rt = tokio::runtime::Runtime::new().unwrap();
    rt.block_on(async {
        // 應用邏輯
    });
}
```

使用方法：
```bash
cargo install tokio-console
tokio-console
```

### Criterion Benchmark

```toml
[dev-dependencies]
criterion = { version = "0.5", features = ["async_tokio"] }

[[bench]]
name = "async_bench"
harness = false
```

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use tokio::runtime::Runtime;

fn async_benchmark(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    
    c.bench_function("async_task", |b| {
        b.to_async(&rt).iter(|| async {
            black_box(expensive_async_operation().await);
        });
    });
}

async fn expensive_async_operation() -> i32 {
    tokio::time::sleep(tokio::time::Duration::from_micros(1)).await;
    42
}

criterion_group!(benches, async_benchmark);
criterion_main!(benches);
```

## 任務調度優化

### 避免任務飢餓

```rust
use tokio::task;

// ❌ 錯誤：長時間運行阻塞調度器
async fn blocking_task() {
    loop {
        // CPU 密集運算，不 yield
        expensive_computation();
    }
}

// ✅ 正確：定期 yield
async fn cooperative_task() {
    loop {
        expensive_computation();
        task::yield_now().await;  // 讓出控制權
    }
}

fn expensive_computation() {
    for _ in 0..1000 {
        std::hint::black_box(1 + 1);
    }
}
```

### 任務批次處理

```rust
use tokio::sync::mpsc;

// ❌ 低效：每條消息獨立處理
async fn process_individually(mut rx: mpsc::Receiver<String>) {
    while let Some(msg) = rx.recv().await {
        process_message(msg).await;
    }
}

// ✅ 高效：批次處理
async fn process_in_batches(mut rx: mpsc::Receiver<String>) {
    let mut batch = Vec::new();
    
    loop {
        tokio::select! {
            Some(msg) = rx.recv() => {
                batch.push(msg);
                if batch.len() >= 100 {
                    process_batch(&batch).await;
                    batch.clear();
                }
            }
            _ = tokio::time::sleep(tokio::time::Duration::from_millis(100)), if !batch.is_empty() => {
                process_batch(&batch).await;
                batch.clear();
            }
        }
    }
}

async fn process_message(msg: String) {
    // 單條處理
}

async fn process_batch(batch: &[String]) {
    // 批次處理，減少系統調用
}
```

### 動態線程池調整

```rust
use tokio::runtime::Builder;

fn create_optimized_runtime() -> tokio::runtime::Runtime {
    let num_cpus = num_cpus::get();
    
    Builder::new_multi_thread()
        .worker_threads(num_cpus)
        .max_blocking_threads(num_cpus * 4)  // IO 密集型
        .thread_name("app-worker")
        .enable_all()
        .build()
        .unwrap()
}
```

## 內存優化

### 減少分配

```rust
use bytes::Bytes;

// ❌ 低效：多次分配
async fn inefficient_copy() -> Vec<u8> {
    let data = vec![0u8; 1024];
    let cloned = data.clone();  // 額外分配
    cloned
}

// ✅ 高效：使用 Bytes（引用計數）
async fn efficient_copy() -> Bytes {
    let data = Bytes::from(vec![0u8; 1024]);
    data.clone()  // 只增加引用計數
}
```

### 對象池 (Object Pool)

```rust
use std::sync::Arc;
use tokio::sync::Mutex;

struct Buffer {
    data: Vec<u8>,
}

struct BufferPool {
    pool: Arc<Mutex<Vec<Buffer>>>,
    capacity: usize,
}

impl BufferPool {
    fn new(capacity: usize) -> Self {
        Self {
            pool: Arc::new(Mutex::new(Vec::new())),
            capacity,
        }
    }
    
    async fn acquire(&self) -> Buffer {
        let mut pool = self.pool.lock().await;
        pool.pop().unwrap_or_else(|| Buffer {
            data: Vec::with_capacity(self.capacity),
        })
    }
    
    async fn release(&self, mut buffer: Buffer) {
        buffer.data.clear();
        let mut pool = self.pool.lock().await;
        if pool.len() < 100 {  // 限制池大小
            pool.push(buffer);
        }
    }
}

#[tokio::main]
async fn main() {
    let pool = Arc::new(BufferPool::new(4096));
    
    let pool_clone = pool.clone();
    tokio::spawn(async move {
        let buffer = pool_clone.acquire().await;
        // 使用 buffer
        pool_clone.release(buffer).await;
    }).await.unwrap();
}
```

### 零拷貝技術

```rust
use bytes::{Bytes, BytesMut};

// 零拷貝分割
fn zero_copy_split() {
    let mut buf = BytesMut::from(&b"Hello, World!"[..]);
    let hello = buf.split_to(5);  // 零拷貝分割
    let world = buf.split_off(2);
    
    println!("{:?} {:?}", hello, world);
}

// 使用 `split` 方法避免克隆
use tokio::io::{AsyncReadExt, AsyncWriteExt};

async fn zero_copy_forward(
    mut reader: tokio::net::TcpStream,
    mut writer: tokio::net::TcpStream,
) -> std::io::Result<()> {
    tokio::io::copy(&mut reader, &mut writer).await?;
    Ok(())
}
```

## 並發控制

### 限流 (Rate Limiting)

```rust
use std::time::{Duration, Instant};
use tokio::sync::Semaphore;
use std::sync::Arc;

struct RateLimiter {
    semaphore: Arc<Semaphore>,
    rate: usize,
    per: Duration,
}

impl RateLimiter {
    fn new(rate: usize, per: Duration) -> Self {
        Self {
            semaphore: Arc::new(Semaphore::new(rate)),
            rate,
            per,
        }
    }
    
    async fn acquire(&self) {
        let _permit = self.semaphore.acquire().await.unwrap();
        
        let sem = self.semaphore.clone();
        let per = self.per;
        tokio::spawn(async move {
            tokio::time::sleep(per).await;
            drop(_permit);
        });
    }
}

#[tokio::main]
async fn main() {
    let limiter = Arc::new(RateLimiter::new(10, Duration::from_secs(1)));
    
    for i in 0..100 {
        let limiter = limiter.clone();
        tokio::spawn(async move {
            limiter.acquire().await;
            println!("Request {}", i);
        });
    }
    
    tokio::time::sleep(Duration::from_secs(15)).await;
}
```

### 自適應並發

```rust
use tokio::sync::Semaphore;
use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};

struct AdaptiveConcurrency {
    semaphore: Arc<Semaphore>,
    permits: AtomicUsize,
    min_permits: usize,
    max_permits: usize,
}

impl AdaptiveConcurrency {
    fn new(initial: usize, min: usize, max: usize) -> Self {
        Self {
            semaphore: Arc::new(Semaphore::new(initial)),
            permits: AtomicUsize::new(initial),
            min_permits: min,
            max_permits: max,
        }
    }
    
    async fn execute<F, Fut>(&self, f: F) -> Fut::Output
    where
        F: FnOnce() -> Fut,
        Fut: std::future::Future,
    {
        let _permit = self.semaphore.acquire().await.unwrap();
        let start = std::time::Instant::now();
        
        let result = f().await;
        
        let latency = start.elapsed();
        self.adjust_concurrency(latency);
        
        result
    }
    
    fn adjust_concurrency(&self, latency: std::time::Duration) {
        let current = self.permits.load(Ordering::Relaxed);
        
        // 簡化的自適應邏輯
        let new_permits = if latency < std::time::Duration::from_millis(100) {
            (current + 1).min(self.max_permits)
        } else if latency > std::time::Duration::from_millis(500) {
            (current.saturating_sub(1)).max(self.min_permits)
        } else {
            current
        };
        
        if new_permits != current {
            self.permits.store(new_permits, Ordering::Relaxed);
            self.semaphore.add_permits(new_permits - current);
        }
    }
}
```

## IO 優化

### 緩衝區調優

```rust
use tokio::io::{BufReader, BufWriter, AsyncReadExt, AsyncWriteExt};
use tokio::fs::File;

#[tokio::main]
async fn main() -> std::io::Result<()> {
    // 增大緩衝區（默認 8KB）
    let file = File::open("large_file.txt").await?;
    let mut reader = BufReader::with_capacity(64 * 1024, file);  // 64KB
    
    let output = File::create("output.txt").await?;
    let mut writer = BufWriter::with_capacity(64 * 1024, output);
    
    let mut buffer = vec![0; 64 * 1024];
    loop {
        let n = reader.read(&mut buffer).await?;
        if n == 0 {
            break;
        }
        writer.write_all(&buffer[..n]).await?;
    }
    
    writer.flush().await?;
    Ok(())
}
```

### 向量化 IO

```rust
use tokio::io::AsyncWriteExt;
use tokio::net::TcpStream;
use std::io::IoSlice;

async fn vectored_write(stream: &mut TcpStream) -> std::io::Result<()> {
    let header = b"HTTP/1.1 200 OK\r\n";
    let body = b"Hello, World!";
    
    let bufs = &[
        IoSlice::new(header),
        IoSlice::new(b"Content-Length: 13\r\n\r\n"),
        IoSlice::new(body),
    ];
    
    stream.write_vectored(bufs).await?;
    Ok(())
}
```

### 零拷貝文件傳輸

```rust
#[cfg(target_os = "linux")]
use tokio::fs::File;
use tokio::net::TcpStream;

#[cfg(target_os = "linux")]
async fn sendfile_example(
    file: &File,
    socket: &TcpStream,
) -> std::io::Result<()> {
    // Tokio 自動使用 sendfile (Linux) / TransmitFile (Windows)
    let mut file = file;
    let mut socket = socket;
    tokio::io::copy(&mut file, &mut socket).await?;
    Ok(())
}
```

## 鎖競爭優化

### 分片鎖 (Sharded Lock)

```rust
use std::collections::HashMap;
use std::hash::{Hash, Hasher};
use std::sync::Arc;
use tokio::sync::RwLock;

const NUM_SHARDS: usize = 16;

struct ShardedMap<K, V> {
    shards: Vec<Arc<RwLock<HashMap<K, V>>>>,
}

impl<K, V> ShardedMap<K, V>
where
    K: Hash + Eq,
{
    fn new() -> Self {
        let shards = (0..NUM_SHARDS)
            .map(|_| Arc::new(RwLock::new(HashMap::new())))
            .collect();
        
        Self { shards }
    }
    
    fn get_shard(&self, key: &K) -> &Arc<RwLock<HashMap<K, V>>> {
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        key.hash(&mut hasher);
        let hash = hasher.finish();
        &self.shards[hash as usize % NUM_SHARDS]
    }
    
    async fn insert(&self, key: K, value: V) -> Option<V> {
        let shard = self.get_shard(&key);
        shard.write().await.insert(key, value)
    }
    
    async fn get(&self, key: &K) -> Option<V>
    where
        V: Clone,
    {
        let shard = self.get_shard(key);
        shard.read().await.get(key).cloned()
    }
}

#[tokio::main]
async fn main() {
    let map = Arc::new(ShardedMap::<String, i32>::new());
    
    let mut handles = vec![];
    for i in 0..100 {
        let map = map.clone();
        let handle = tokio::spawn(async move {
            map.insert(format!("key{}", i), i).await;
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.await.unwrap();
    }
}
```

### 無鎖數據結構

```rust
use std::sync::Arc;
use crossbeam::queue::SegQueue;

#[tokio::main]
async fn main() {
    let queue = Arc::new(SegQueue::new());
    
    // 生產者
    let queue_clone = queue.clone();
    tokio::spawn(async move {
        for i in 0..100 {
            queue_clone.push(i);
        }
    });
    
    // 消費者
    tokio::spawn(async move {
        loop {
            if let Some(value) = queue.pop() {
                println!("Consumed: {}", value);
            } else {
                tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
            }
        }
    }).await.unwrap();
}
```

## 編譯優化

### Cargo 配置

```toml
# Cargo.toml
[profile.release]
opt-level = 3              # 最高優化級別
lto = "fat"                # Link Time Optimization
codegen-units = 1          # 單個代碼生成單元（更好的優化）
panic = "abort"            # Panic 時直接 abort（減小二進制大小）
strip = true               # 移除符號信息

[profile.release-with-debug]
inherits = "release"
debug = true               # 保留調試信息用於性能分析
```

### CPU 特定優化

```bash
# 使用本機 CPU 指令集
RUSTFLAGS="-C target-cpu=native" cargo build --release

# 特定架構優化
RUSTFLAGS="-C target-feature=+avx2" cargo build --release
```

## 異步生態優化

### 選擇合適的運行時

```rust
// Tokio：通用高性能
#[tokio::main]
async fn tokio_example() {
    // 適合：Web 服務、網路應用
}

// async-std：API 類似標準庫
#[async_std::main]
async fn async_std_example() {
    // 適合：原型開發、教學
}

// smol：輕量級
fn smol_example() {
    smol::block_on(async {
        // 適合：嵌入式、低資源環境
    });
}
```

### 避免不必要的 Box

```rust
// ❌ 不必要的堆分配
type BoxFuture<T> = std::pin::Pin<Box<dyn std::future::Future<Output = T> + Send>>;

fn returns_boxed() -> BoxFuture<i32> {
    Box::pin(async { 42 })
}

// ✅ 使用 impl Future
async fn returns_impl() -> i32 {
    42
}
```

## 性能監控

### 自定義指標

```rust
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;

struct Metrics {
    requests: AtomicU64,
    errors: AtomicU64,
    latency_sum: AtomicU64,
}

impl Metrics {
    fn new() -> Self {
        Self {
            requests: AtomicU64::new(0),
            errors: AtomicU64::new(0),
            latency_sum: AtomicU64::new(0),
        }
    }
    
    fn record_request(&self, latency_ms: u64, is_error: bool) {
        self.requests.fetch_add(1, Ordering::Relaxed);
        self.latency_sum.fetch_add(latency_ms, Ordering::Relaxed);
        if is_error {
            self.errors.fetch_add(1, Ordering::Relaxed);
        }
    }
    
    fn report(&self) {
        let requests = self.requests.load(Ordering::Relaxed);
        let errors = self.errors.load(Ordering::Relaxed);
        let avg_latency = if requests > 0 {
            self.latency_sum.load(Ordering::Relaxed) / requests
        } else {
            0
        };
        
        println!("Requests: {}, Errors: {}, Avg Latency: {}ms", 
                 requests, errors, avg_latency);
    }
}

#[tokio::main]
async fn main() {
    let metrics = Arc::new(Metrics::new());
    
    let metrics_clone = metrics.clone();
    tokio::spawn(async move {
        loop {
            tokio::time::sleep(tokio::time::Duration::from_secs(10)).await;
            metrics_clone.report();
        }
    });
    
    // 模擬請求
    for _ in 0..1000 {
        let metrics = metrics.clone();
        tokio::spawn(async move {
            let start = std::time::Instant::now();
            // 處理請求
            tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
            let latency = start.elapsed().as_millis() as u64;
            metrics.record_request(latency, false);
        });
    }
    
    tokio::time::sleep(tokio::time::Duration::from_secs(30)).await;
}
```

---

## 參考資料

1. [Tokio Performance Tuning](https://tokio.rs/tokio/topics/performance)
2. [Async Rust Performance](https://matklad.github.io/2023/01/04/on-async-performance.html)
3. [Optimizing Async Rust](https://blog.yoshuawuyts.com/async-finalizers/)
4. [The Rust Performance Book](https://nnethercote.github.io/perf-book/)
5. [Tokio Console](https://docs.rs/console-subscriber/)
6. 《Zero Cost Abstractions in Async Rust》(Jon Gjengset)
