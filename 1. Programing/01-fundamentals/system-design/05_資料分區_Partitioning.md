# 05 - è³‡æ–™åˆ†å€ (Partitioning)

## ğŸ¯ å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬ç« å¾Œ,ä½ å°‡èƒ½å¤ :
- ç†è§£è³‡æ–™åˆ†å€çš„ç›®çš„èˆ‡æŒ‘æˆ°
- æŒæ¡ä¸»æµåˆ†å€ç­–ç•¥çš„åŸç†èˆ‡æ‡‰ç”¨å ´æ™¯
- è¨­è¨ˆåˆç†çš„åˆ†å€æ–¹æ¡ˆé¿å…ç†±é»å•é¡Œ
- è™•ç†åˆ†å€é‡å¹³è¡¡èˆ‡è·¯ç”±æ©Ÿåˆ¶

---

## ğŸ’¡ æ ¸å¿ƒæ¦‚å¿µ

### ä»€éº¼æ˜¯è³‡æ–™åˆ†å€?

**è³‡æ–™åˆ†å€ (Partitioning/Sharding)** æ˜¯å°‡å¤§å‹è³‡æ–™é›†æ‹†åˆ†æˆå¤šå€‹è¼ƒå°çš„**åˆ†å€ (Partition)** æˆ–**åˆ†ç‰‡ (Shard)**,ä¸¦åˆ†æ•£å­˜å„²åœ¨ä¸åŒç¯€é»ä¸Šã€‚

```mermaid
graph TD
    A["å®Œæ•´è³‡æ–™é›†<br/>10TB è³‡æ–™"] --> B["åˆ†å€ 1<br/>2TB<br/>ç¯€é» A"]
    A --> C["åˆ†å€ 2<br/>2TB<br/>ç¯€é» B"]
    A --> D["åˆ†å€ 3<br/>2TB<br/>ç¯€é» C"]
    A --> E["åˆ†å€ 4<br/>2TB<br/>ç¯€é» D"]
    A --> F["åˆ†å€ 5<br/>2TB<br/>ç¯€é» E"]
    
    style A fill:#ffcccc
    style B fill:#ccffcc
    style C fill:#ccffcc
    style D fill:#ccffcc
    style E fill:#ccffcc
    style F fill:#ccffcc
```

**ç‚ºä»€éº¼éœ€è¦åˆ†å€?**

1. **æ“´å±•æ€§ (Scalability)**: å–®æ©Ÿå­˜å„²å®¹é‡æœ‰é™
2. **ååé‡ (Throughput)**: åˆ†æ•£è² è¼‰åˆ°å¤šå°æ©Ÿå™¨
3. **æŸ¥è©¢æ•ˆèƒ½**: ä¸¦è¡ŒæŸ¥è©¢å¤šå€‹åˆ†å€

**èˆ‡è¤‡è£½çš„é—œä¿‚**:

```mermaid
graph LR
    subgraph P1["åˆ†å€ 1"]
        P1L["ä¸»å‰¯æœ¬"]
        P1F1["å¾å‰¯æœ¬ 1"]
        P1F2["å¾å‰¯æœ¬ 2"]
    end
    
    subgraph P2["åˆ†å€ 2"]
        P2L["ä¸»å‰¯æœ¬"]
        P2F1["å¾å‰¯æœ¬ 1"]
        P2F2["å¾å‰¯æœ¬ 2"]
    end
    
    style P1L fill:#ff9999
    style P2L fill:#ff9999
    style P1F1 fill:#99ccff
    style P1F2 fill:#99ccff
    style P2F1 fill:#99ccff
    style P2F2 fill:#99ccff
```

**åˆ†å€ + è¤‡è£½**: æ¯å€‹åˆ†å€é€šå¸¸æœ‰å¤šå€‹å‰¯æœ¬,å…¼é¡§æ“´å±•æ€§èˆ‡é«˜å¯ç”¨æ€§ã€‚

---

## ğŸ“Š åˆ†å€ç­–ç•¥

### ç­–ç•¥ 1: åŸºæ–¼éµç¯„åœçš„åˆ†å€ (Range-based Partitioning)

**åŸç†**: å°‡é€£çºŒçš„éµç¯„åœåˆ†é…åˆ°ä¸åŒåˆ†å€ã€‚

```mermaid
graph LR
    A["æ‰€æœ‰è³‡æ–™"] --> B["åˆ†å€ 1<br/>A-F"]
    A --> C["åˆ†å€ 2<br/>G-M"]
    A --> D["åˆ†å€ 3<br/>N-S"]
    A --> E["åˆ†å€ 4<br/>T-Z"]
```

**ç¤ºä¾‹: ç”¨æˆ¶è¡¨æŒ‰å§“æ°åˆ†å€**

| åˆ†å€ | éµç¯„åœ | å­˜å„²ç¯€é» |
|------|--------|----------|
| P1 | A-F | ç¯€é» 1 |
| P2 | G-M | ç¯€é» 2 |
| P3 | N-S | ç¯€é» 3 |
| P4 | T-Z | ç¯€é» 4 |

### ğŸ’» å¯¦ä½œç¯„ä¾‹

```python
class RangePartitioner:
    def __init__(self, ranges):
        """
        ranges: [(end_key, partition_id), ...]
        ä¾‹å¦‚: [('F', 0), ('M', 1), ('S', 2), ('Z', 3)]
        """
        self.ranges = sorted(ranges)
    
    def get_partition(self, key):
        """æ ¹æ“šéµè¿”å›åˆ†å€ ID"""
        for end_key, partition_id in self.ranges:
            if key <= end_key:
                return partition_id
        return self.ranges[-1][1]  # è¶…å‡ºç¯„åœä½¿ç”¨æœ€å¾Œåˆ†å€
    
    # ä½¿ç”¨ç¯„ä¾‹
    partitioner = RangePartitioner([
        ('F', 0), ('M', 1), ('S', 2), ('Z', 3)
    ])
    
    print(partitioner.get_partition('Alice'))   # 0 (A-F)
    print(partitioner.get_partition('Charlie')) # 0 (A-F)
    print(partitioner.get_partition('Mike'))    # 1 (G-M)
    print(partitioner.get_partition('Zara'))    # 3 (T-Z)
```

**âœ… å„ªé»**:
- æ”¯æŒ**ç¯„åœæŸ¥è©¢**: `SELECT * FROM users WHERE name BETWEEN 'A' AND 'D'` åªéœ€æŸ¥è©¢åˆ†å€ 1
- éµçš„é †åºè¢«ä¿ç•™

**âŒ ç¼ºé»**:
- **ç†±é»å•é¡Œ (Hot Spot)**: å¦‚æœéµçš„åˆ†å¸ƒä¸å‡,æŸäº›åˆ†å€æœƒéè¼‰

**ğŸ¢ çœŸå¯¦æ¡ˆä¾‹: HBase**

- æŒ‰è¡Œéµ (Row Key) çš„å­—å…¸åºåˆ†å€
- æ¯å€‹**å€åŸŸ (Region)** å­˜å„²é€£çºŒçš„è¡Œç¯„åœ
- æ”¯æŒé«˜æ•ˆçš„ç¯„åœæƒæ

```java
// HBase ç¯„åœæƒæ
Scan scan = new Scan();
scan.setStartRow(Bytes.toBytes("user_2023"));
scan.setStopRow(Bytes.toBytes("user_2024"));
ResultScanner scanner = table.getScanner(scan);
```

---

### ç­–ç•¥ 2: åŸºæ–¼é›œæ¹Šçš„åˆ†å€ (Hash-based Partitioning)

**åŸç†**: å°éµè¨ˆç®—é›œæ¹Šå€¼,æ ¹æ“šé›œæ¹Šå€¼åˆ†é…åˆ†å€ã€‚

```mermaid
graph LR
    A["éµ: 'Alice'"] --> B["é›œæ¹Šå‡½æ•¸"]
    B --> C["é›œæ¹Šå€¼: 42"]
    C --> D["42 % 4 = 2"]
    D --> E["åˆ†å€ 2"]
```

### ğŸ’» å¯¦ä½œç¯„ä¾‹

```python
import hashlib

class HashPartitioner:
    def __init__(self, num_partitions):
        self.num_partitions = num_partitions
    
    def get_partition(self, key):
        # ä½¿ç”¨ MD5 é›œæ¹Š
        hash_value = int(hashlib.md5(key.encode()).hexdigest(), 16)
        return hash_value % self.num_partitions

# ä½¿ç”¨ç¯„ä¾‹
partitioner = HashPartitioner(num_partitions=4)

print(partitioner.get_partition('Alice'))   # å¯èƒ½è¼¸å‡º: 1
print(partitioner.get_partition('Bob'))     # å¯èƒ½è¼¸å‡º: 3
print(partitioner.get_partition('Charlie')) # å¯èƒ½è¼¸å‡º: 0
print(partitioner.get_partition('Diana'))   # å¯èƒ½è¼¸å‡º: 2
```

**è³‡æ–™åˆ†å¸ƒç¤ºä¾‹**:

```python
# æ¸¬è©¦é›œæ¹Šåˆ†å€çš„å‡å‹»æ€§
from collections import Counter

partitioner = HashPartitioner(num_partitions=4)
keys = [f"user_{i}" for i in range(10000)]
distribution = Counter(partitioner.get_partition(key) for key in keys)

print(distribution)
# è¼¸å‡º: Counter({0: 2503, 1: 2487, 2: 2521, 3: 2489})
# åˆ†å¸ƒç›¸å°å‡å‹»
```

**âœ… å„ªé»**:
- **å‡å‹»åˆ†å¸ƒ**: é¿å…ç†±é»å•é¡Œ
- å¯¦ä½œç°¡å–®

**âŒ ç¼ºé»**:
- **ç„¡æ³•ç¯„åœæŸ¥è©¢**: éµçš„é †åºè¢«æ‰“äº‚
- **é‡æ–°åˆ†å€æˆæœ¬é«˜**: æ·»åŠ /ç§»é™¤ç¯€é»æ™‚éœ€è¦é‡æ–°è¨ˆç®—å¤§é‡è³‡æ–™çš„åˆ†å€

**ğŸ¢ çœŸå¯¦æ¡ˆä¾‹: Cassandra**

- ä½¿ç”¨**ä¸€è‡´æ€§é›œæ¹Š (Consistent Hashing)** çš„è®Šé«” (Token Ring)
- æ¯å€‹ç¯€é»è² è²¬é›œæ¹Šç’°ä¸Šçš„ä¸€å€‹ç¯„åœ
- æ·»åŠ ç¯€é»æ™‚åªéœ€ç§»å‹•éƒ¨åˆ†è³‡æ–™

---

### ç­–ç•¥ 3: ä¸€è‡´æ€§é›œæ¹Š (Consistent Hashing)

**å•é¡Œ**: æ™®é€šé›œæ¹Šåˆ†å€åœ¨æ·»åŠ /ç§»é™¤ç¯€é»æ™‚,å¹¾ä¹æ‰€æœ‰éµéœ€è¦é‡æ–°åˆ†é…ã€‚

**ç¯„ä¾‹**:
```python
# 4 å€‹ç¯€é»æ™‚
key = "Alice"
partition = hash(key) % 4  # å‡è¨­çµæœ = 2

# å¢åŠ åˆ° 5 å€‹ç¯€é»å¾Œ
partition = hash(key) % 5  # å‡è¨­çµæœ = 4 (æ”¹è®Šäº†!)
```

**ä¸€è‡´æ€§é›œæ¹Šè§£æ±ºæ–¹æ¡ˆ**:

```mermaid
graph TD
    A["é›œæ¹Šç’° (0 - 2^32)"]
    
    subgraph Ring["é›œæ¹Šç’°"]
        N1["ç¯€é» A<br/>é›œæ¹Šå€¼: 100"]
        N2["ç¯€é» B<br/>é›œæ¹Šå€¼: 200"]
        N3["ç¯€é» C<br/>é›œæ¹Šå€¼: 300"]
        K1["éµ 'Alice'<br/>é›œæ¹Šå€¼: 150"]
        K2["éµ 'Bob'<br/>é›œæ¹Šå€¼: 250"]
    end
    
    K1 -->|é †æ™‚é‡æ‰¾åˆ°<br/>ç¬¬ä¸€å€‹ç¯€é»| N2
    K2 -->|é †æ™‚é‡æ‰¾åˆ°<br/>ç¬¬ä¸€å€‹ç¯€é»| N3
```

### ğŸ’» å¯¦ä½œç¯„ä¾‹

```python
import hashlib
import bisect

class ConsistentHash:
    def __init__(self, num_replicas=150):
        self.num_replicas = num_replicas  # è™›æ“¬ç¯€é»æ•¸
        self.ring = {}  # {hash_value: node_id}
        self.sorted_keys = []
    
    def _hash(self, key):
        return int(hashlib.md5(key.encode()).hexdigest(), 16)
    
    def add_node(self, node_id):
        """æ·»åŠ ç¯€é» (åŒ…å«è™›æ“¬ç¯€é»)"""
        for i in range(self.num_replicas):
            virtual_key = f"{node_id}:{i}"
            hash_value = self._hash(virtual_key)
            self.ring[hash_value] = node_id
            bisect.insort(self.sorted_keys, hash_value)
    
    def remove_node(self, node_id):
        """ç§»é™¤ç¯€é»"""
        for i in range(self.num_replicas):
            virtual_key = f"{node_id}:{i}"
            hash_value = self._hash(virtual_key)
            del self.ring[hash_value]
            self.sorted_keys.remove(hash_value)
    
    def get_node(self, key):
        """æ‰¾åˆ°è² è²¬è©²éµçš„ç¯€é»"""
        if not self.ring:
            return None
        
        hash_value = self._hash(key)
        # æ‰¾åˆ°ç¬¬ä¸€å€‹ >= hash_value çš„ç¯€é»
        idx = bisect.bisect_right(self.sorted_keys, hash_value)
        if idx == len(self.sorted_keys):
            idx = 0  # ç’°å½¢,å›åˆ°èµ·é»
        
        return self.ring[self.sorted_keys[idx]]

# ä½¿ç”¨ç¯„ä¾‹
ch = ConsistentHash(num_replicas=150)
ch.add_node("node1")
ch.add_node("node2")
ch.add_node("node3")

print(ch.get_node("Alice"))   # node2
print(ch.get_node("Bob"))     # node1

# æ·»åŠ æ–°ç¯€é»
ch.add_node("node4")
print(ch.get_node("Alice"))   # å¯èƒ½é‚„æ˜¯ node2 (å¤§éƒ¨åˆ†éµä¸è®Š!)
```

**è™›æ“¬ç¯€é» (Virtual Nodes)** çš„ä½œç”¨:

```mermaid
graph LR
    A["ç‰©ç†ç¯€é» A"] --> V1["è™›æ“¬ç¯€é» A:0"]
    A --> V2["è™›æ“¬ç¯€é» A:1"]
    A --> V3["è™›æ“¬ç¯€é» A:2"]
    
    B["ç‰©ç†ç¯€é» B"] --> V4["è™›æ“¬ç¯€é» B:0"]
    B --> V5["è™›æ“¬ç¯€é» B:1"]
    B --> V6["è™›æ“¬ç¯€é» B:2"]
```

**å¥½è™•**: è² è¼‰åˆ†å¸ƒæ›´å‡å‹»,é¿å…ç¯€é»è² è²¬çš„é›œæ¹Šç¯„åœéå¤§æˆ–éå°ã€‚

**âœ… å„ªé»**:
- æ·»åŠ /ç§»é™¤ç¯€é»æ™‚,åªæœ‰ **1/N** çš„éµéœ€è¦é‡æ–°åˆ†é… (N ç‚ºç¯€é»æ•¸)
- è² è¼‰ç›¸å°å‡å‹»

**âŒ ç¼ºé»**:
- å¯¦ä½œè¼ƒè¤‡é›œ
- ä»ç„¡æ³•æ”¯æŒç¯„åœæŸ¥è©¢

---

## ğŸ”¥ ç†±é»å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### ä»€éº¼æ˜¯ç†±é»?

**ç†±é» (Hot Spot)** æŒ‡æŸå€‹åˆ†å€æ‰¿å—é é«˜æ–¼å¹³å‡æ°´å¹³çš„è² è¼‰ã€‚

**å¸¸è¦‹åŸå› **:

```mermaid
graph TD
    A["ç†±é»åŸå› "] --> B["éµåˆ†å¸ƒä¸å‡<br/>å¦‚: åäººç”¨æˆ¶"]
    A --> C["æ™‚é–“åºåˆ—è³‡æ–™<br/>å¦‚: ç•¶å‰æ™‚é–“çš„åˆ†å€"]
    A --> D["ç‰¹å®šæ¥­å‹™é‚è¼¯<br/>å¦‚: ç†±é–€å•†å“"]
```

### æ¡ˆä¾‹ 1: ç¤¾äº¤åª’é«”åäººè³¬è™Ÿ

**å•é¡Œ**:
- ç”¨æˆ¶ ID ä½œç‚ºåˆ†å€éµ
- åäººè³¬è™Ÿ (åƒè¬ç²‰çµ²) å’Œæ™®é€šç”¨æˆ¶ (å¹¾åç²‰çµ²) åœ¨åŒä¸€åˆ†å€ç­–ç•¥ä¸‹
- åäººè³¬è™Ÿçš„åˆ†å€æ‰¿å—å·¨å¤§çš„è®€å–å£“åŠ›

```python
# å•é¡Œç¤ºä¾‹
partitioner = HashPartitioner(num_partitions=10)

# æ™®é€šç”¨æˆ¶
normal_user = "user_12345"
partition = partitioner.get_partition(normal_user)  # å‡è¨­ = 3

# åäººç”¨æˆ¶
celebrity = "user_celebrity"
partition = partitioner.get_partition(celebrity)  # å‡è¨­ä¹Ÿ = 3

# åˆ†å€ 3 æ‰¿å—å¤§é‡è®€å–å£“åŠ›!
```

**è§£æ±ºæ–¹æ¡ˆ**:

#### æ–¹æ¡ˆ 1: åˆ†è£‚ç†±éµ (Key Splitting)

```python
class HotKeyPartitioner:
    def __init__(self, num_partitions, hot_keys, split_factor=10):
        self.num_partitions = num_partitions
        self.hot_keys = hot_keys  # éœ€è¦åˆ†è£‚çš„ç†±éµé›†åˆ
        self.split_factor = split_factor
    
    def get_partitions(self, key):
        """è¿”å›éµå°æ‡‰çš„æ‰€æœ‰åˆ†å€"""
        if key in self.hot_keys:
            # ç†±éµåˆ†è£‚æˆå¤šå€‹å­éµ
            base_hash = hash(key)
            return [
                (base_hash + i) % self.num_partitions 
                for i in range(self.split_factor)
            ]
        else:
            return [hash(key) % self.num_partitions]
    
    def write(self, key, value):
        """å¯«å…¥æ‰€æœ‰ç›¸é—œåˆ†å€"""
        partitions = self.get_partitions(key)
        for partition in partitions:
            self.write_to_partition(partition, key, value)
    
    def read(self, key):
        """å¾éš¨æ©Ÿä¸€å€‹åˆ†å€è®€å–"""
        import random
        partitions = self.get_partitions(key)
        partition = random.choice(partitions)
        return self.read_from_partition(partition, key)

# ä½¿ç”¨ç¯„ä¾‹
partitioner = HotKeyPartitioner(
    num_partitions=10,
    hot_keys={'celebrity_user_1', 'celebrity_user_2'}
)

# æ™®é€šç”¨æˆ¶: 1 å€‹åˆ†å€
print(partitioner.get_partitions('normal_user'))
# è¼¸å‡º: [3]

# åäººç”¨æˆ¶: 10 å€‹åˆ†å€ (åˆ†æ•£è®€å–å£“åŠ›)
print(partitioner.get_partitions('celebrity_user_1'))
# è¼¸å‡º: [7, 8, 9, 0, 1, 2, 3, 4, 5, 6]
```

#### æ–¹æ¡ˆ 2: åŠ å…¥éš¨æ©Ÿå‰ç¶´

```python
import random

def write_with_prefix(key, value, num_replicas=10):
    """å¯«å…¥æ™‚åŠ å…¥éš¨æ©Ÿå‰ç¶´"""
    for i in range(num_replicas):
        prefixed_key = f"{i}_{key}"
        write_to_db(prefixed_key, value)

def read_with_prefix(key, num_replicas=10):
    """è®€å–æ™‚éš¨æ©Ÿé¸æ“‡ä¸€å€‹å‰ç¶´"""
    prefix = random.randint(0, num_replicas - 1)
    prefixed_key = f"{prefix}_{key}"
    return read_from_db(prefixed_key)

# ä½¿ç”¨ç¯„ä¾‹
write_with_prefix("celebrity_user", {"followers": 10000000})

# è®€å–æ™‚è² è¼‰åˆ†æ•£åˆ° 10 å€‹éµ
value1 = read_with_prefix("celebrity_user")  # å¯èƒ½è®€å– "3_celebrity_user"
value2 = read_with_prefix("celebrity_user")  # å¯èƒ½è®€å– "7_celebrity_user"
```

### æ¡ˆä¾‹ 2: æ™‚é–“åºåˆ—è³‡æ–™

**å•é¡Œ**:
- ä½¿ç”¨æ™‚é–“æˆ³ä½œç‚ºåˆ†å€éµ
- æ‰€æœ‰ç•¶å‰çš„å¯«å…¥éƒ½é›†ä¸­åœ¨æœ€æ–°çš„åˆ†å€

```python
# æŒ‰æ—¥æœŸåˆ†å€
def get_partition(timestamp):
    date = timestamp.date()
    return hash(date) % num_partitions

# 2024-01-15 çš„æ‰€æœ‰è³‡æ–™å¯«å…¥åŒä¸€åˆ†å€ (ç†±é»!)
```

**è§£æ±ºæ–¹æ¡ˆ: è¤‡åˆåˆ†å€éµ**

```python
def get_partition(sensor_id, timestamp):
    # ä½¿ç”¨ sensor_id + æ—¥æœŸä½œç‚ºè¤‡åˆéµ
    date = timestamp.date()
    composite_key = f"{sensor_id}_{date}"
    return hash(composite_key) % num_partitions

# åŒä¸€å¤©çš„è³‡æ–™æ ¹æ“š sensor_id åˆ†æ•£åˆ°å¤šå€‹åˆ†å€
partition1 = get_partition("sensor_001", datetime(2024, 1, 15))
partition2 = get_partition("sensor_002", datetime(2024, 1, 15))
# partition1 != partition2
```

**âš–ï¸ æ¬Šè¡¡**: ç¯„åœæŸ¥è©¢ (å¦‚æŸ¥è©¢æŸå¤©çš„æ‰€æœ‰è³‡æ–™) éœ€è¦æƒæå¤šå€‹åˆ†å€ã€‚

---

## ğŸ”„ åˆ†å€é‡å¹³è¡¡ (Rebalancing)

### ç‚ºä»€éº¼éœ€è¦é‡å¹³è¡¡?

**è§¸ç™¼å ´æ™¯**:
1. è³‡æ–™é‡å¢é•·,éœ€è¦å¢åŠ ç¯€é»
2. ç¯€é»æ•…éšœ,éœ€è¦ç§»é™¤ç¯€é»
3. ç¡¬é«”å‡ç´š

**ç›®æ¨™**:
- é‡æ–°åˆ†é…åˆ†å€,ä½¿è² è¼‰å‡å‹»
- ç›¡é‡æ¸›å°‘è³‡æ–™ç§»å‹•
- æœå‹™æŒçºŒå¯ç”¨

### ç­–ç•¥ 1: å›ºå®šæ•¸é‡çš„åˆ†å€

**è¨­è¨ˆ**:
- å‰µå»º**é å¤šæ–¼ç¯€é»æ•¸**çš„åˆ†å€ (å¦‚ 1000 å€‹åˆ†å€,10 å€‹ç¯€é»)
- æ¯å€‹ç¯€é»è² è²¬å¤šå€‹åˆ†å€
- æ·»åŠ ç¯€é»æ™‚,å¾ç¾æœ‰ç¯€é»è½‰ç§»éƒ¨åˆ†åˆ†å€

```mermaid
graph TD
    subgraph Before["é‡å¹³è¡¡å‰ (2 å€‹ç¯€é»)"]
        N1["ç¯€é» 1<br/>åˆ†å€: 1,2,3,4,5"]
        N2["ç¯€é» 2<br/>åˆ†å€: 6,7,8,9,10"]
    end
    
    subgraph After["é‡å¹³è¡¡å¾Œ (3 å€‹ç¯€é»)"]
        N1A["ç¯€é» 1<br/>åˆ†å€: 1,2,3"]
        N2A["ç¯€é» 2<br/>åˆ†å€: 6,7,8"]
        N3["ç¯€é» 3 (æ–°)<br/>åˆ†å€: 4,5,9,10"]
    end
    
    Before --> After
```

**ğŸ’» å¯¦ä½œç¯„ä¾‹**:

```python
class FixedPartitionRebalancer:
    def __init__(self, num_partitions=1000):
        self.num_partitions = num_partitions
        self.partition_to_node = {}  # {partition_id: node_id}
    
    def initial_assignment(self, nodes):
        """åˆå§‹åˆ†é…"""
        for partition in range(self.num_partitions):
            node = nodes[partition % len(nodes)]
            self.partition_to_node[partition] = node
    
    def add_node(self, new_node, existing_nodes):
        """æ·»åŠ æ–°ç¯€é»,é‡æ–°åˆ†é…éƒ¨åˆ†åˆ†å€"""
        target_per_node = self.num_partitions // (len(existing_nodes) + 1)
        
        # å¾æ¯å€‹ç¾æœ‰ç¯€é»è½‰ç§»ä¸€äº›åˆ†å€åˆ°æ–°ç¯€é»
        transferred = 0
        for partition, node in list(self.partition_to_node.items()):
            if node in existing_nodes and transferred < target_per_node:
                self.partition_to_node[partition] = new_node
                transferred += 1
    
    def get_node(self, key):
        partition = hash(key) % self.num_partitions
        return self.partition_to_node[partition]

# ä½¿ç”¨ç¯„ä¾‹
rebalancer = FixedPartitionRebalancer(num_partitions=1000)
rebalancer.initial_assignment(['node1', 'node2'])

# node1 å’Œ node2 å„è² è²¬ 500 å€‹åˆ†å€
print(rebalancer.get_node('Alice'))  # node1 æˆ– node2

# æ·»åŠ  node3
rebalancer.add_node('node3', ['node1', 'node2'])
# ç¾åœ¨æ¯å€‹ç¯€é»è² è²¬ç´„ 333 å€‹åˆ†å€
```

**ğŸ¢ çœŸå¯¦æ¡ˆä¾‹: Riak, Elasticsearch**

- Elasticsearch é»˜èªæ¯å€‹ç´¢å¼• 5 å€‹ä¸»åˆ†ç‰‡ (Primary Shard)
- åˆ†ç‰‡æ•¸å‰µå»ºå¾Œä¸å¯æ”¹è®Š
- æ·»åŠ ç¯€é»æ™‚é‡æ–°åˆ†é…åˆ†ç‰‡

**âœ… å„ªé»**:
- æ“ä½œç°¡å–®,åªéœ€ç§»å‹•æ•´å€‹åˆ†å€
- åˆ†å€æ•¸é‡å›ºå®š,ä¾¿æ–¼ç®¡ç†

**âŒ ç¼ºé»**:
- åˆ†å€æ•¸éœ€è¦é å…ˆè¦åŠƒ (å¤ªå°‘æœƒé™åˆ¶æ“´å±•,å¤ªå¤šæœƒå¢åŠ é–‹éŠ·)

---

### ç­–ç•¥ 2: å‹•æ…‹åˆ†å€

**è¨­è¨ˆ**:
- åˆ†å€æ ¹æ“šè³‡æ–™å¤§å°**è‡ªå‹•åˆ†è£‚æˆ–åˆä½µ**
- é¡ä¼¼ B-Tree çš„åˆ†è£‚ç­–ç•¥

```mermaid
graph LR
    A["åˆ†å€ 1<br/>10GB"] -->|è¶…éé–¾å€¼<br/>åˆ†è£‚| B["åˆ†å€ 1a<br/>5GB"]
    A -->|è¶…éé–¾å€¼<br/>åˆ†è£‚| C["åˆ†å€ 1b<br/>5GB"]
```

**åˆ†è£‚æ¢ä»¶**: ç•¶åˆ†å€å¤§å°è¶…éé–¾å€¼ (å¦‚ 10GB) æ™‚åˆ†è£‚æˆå…©å€‹åˆ†å€

**åˆä½µæ¢ä»¶**: ç•¶åˆ†å€å¤§å°ä½æ–¼é–¾å€¼ (å¦‚ 1GB) æ™‚åˆä½µç›¸é„°åˆ†å€

**ğŸ¢ çœŸå¯¦æ¡ˆä¾‹: HBase, MongoDB**

HBase Region åˆ†è£‚:
```java
// HBase è‡ªå‹•åˆ†è£‚é…ç½®
hbase.hregion.max.filesize = 10737418240  // 10GB
```

**âœ… å„ªé»**:
- è‡ªå‹•é©æ‡‰è³‡æ–™é‡è®ŠåŒ–
- ç„¡éœ€é å…ˆè¦åŠƒåˆ†å€æ•¸

**âŒ ç¼ºé»**:
- åˆå§‹åªæœ‰ä¸€å€‹åˆ†å€ (éœ€è¦é åˆ†å€é¿å…æ—©æœŸç“¶é ¸)
- åˆ†è£‚æ“ä½œå¯èƒ½å½±éŸ¿æ€§èƒ½

---

### ç­–ç•¥ 3: æŒ‰ç¯€é»æ¯”ä¾‹åˆ†å€

**è¨­è¨ˆ**:
- æ¯å€‹ç¯€é»è² è²¬å›ºå®šæ•¸é‡çš„åˆ†å€ (å¦‚æ¯å€‹ç¯€é» 256 å€‹åˆ†å€)
- æ·»åŠ ç¯€é»æ™‚,éš¨æ©Ÿé¸æ“‡ç¾æœ‰åˆ†å€é€²è¡Œåˆ†è£‚

**ğŸ¢ çœŸå¯¦æ¡ˆä¾‹: Cassandra**

- æ¯å€‹ç¯€é»é…ç½®å›ºå®šæ•¸é‡çš„è™›æ“¬ç¯€é» (vnodes)
- é»˜èªæ¯å€‹ç¯€é» 256 å€‹ vnodes

**âœ… å„ªé»**:
- èˆ‡ç¯€é»æ•¸æˆæ¯”ä¾‹,è‡ªå‹•æ“´å±•

**âŒ ç¼ºé»**:
- å¯¦ä½œè¤‡é›œ

---

## ğŸ—ºï¸ è·¯ç”±æ©Ÿåˆ¶ (Request Routing)

### å•é¡Œ: å®¢æˆ¶ç«¯å¦‚ä½•çŸ¥é“è¨ªå•å“ªå€‹ç¯€é»?

**ä¸‰ç¨®è·¯ç”±æ–¹æ¡ˆ**:

```mermaid
graph TD
    A["è·¯ç”±æ–¹æ¡ˆ"] --> B["æ–¹æ¡ˆ 1: å®¢æˆ¶ç«¯è·¯ç”±<br/>å®¢æˆ¶ç«¯çŸ¥é“åˆ†å€æ˜ å°„"]
    A --> C["æ–¹æ¡ˆ 2: è·¯ç”±å±¤<br/>ç¨ç«‹çš„è·¯ç”±æœå‹™"]
    A --> D["æ–¹æ¡ˆ 3: ç¯€é»è½‰ç™¼<br/>ä»»æ„ç¯€é»æ¥æ”¶,å…§éƒ¨è½‰ç™¼"]
```

### æ–¹æ¡ˆ 1: å®¢æˆ¶ç«¯è·¯ç”±

**æ¶æ§‹**:

```mermaid
graph LR
    Client["å®¢æˆ¶ç«¯<br/>(å…§å»ºåˆ†å€é‚è¼¯)"] -->|ç›´æ¥é€£æ¥| N1["ç¯€é» 1"]
    Client -->|ç›´æ¥é€£æ¥| N2["ç¯€é» 2"]
    Client -->|ç›´æ¥é€£æ¥| N3["ç¯€é» 3"]
```

**å¯¦ä½œç¯„ä¾‹**:

```python
class SmartClient:
    def __init__(self, nodes):
        self.nodes = nodes
        self.partitioner = ConsistentHash()
        for node in nodes:
            self.partitioner.add_node(node)
    
    def get(self, key):
        # å®¢æˆ¶ç«¯è¨ˆç®—åˆ†å€
        node = self.partitioner.get_node(key)
        return self.send_request(node, f"GET {key}")
    
    def put(self, key, value):
        node = self.partitioner.get_node(key)
        return self.send_request(node, f"PUT {key} {value}")

# ä½¿ç”¨ç¯„ä¾‹
client = SmartClient(['node1:9000', 'node2:9000', 'node3:9000'])
value = client.get('Alice')
```

**ğŸ¢ çœŸå¯¦æ¡ˆä¾‹: Cassandra, Memcached å®¢æˆ¶ç«¯**

**âœ… å„ªé»**: æ¸›å°‘ç¶²è·¯è·³è½‰,ä½å»¶é²

**âŒ ç¼ºé»**: å®¢æˆ¶ç«¯éœ€è¦çŸ¥é“é›†ç¾¤æ‹“æ’²,å‹•æ…‹è®Šæ›´æ™‚éœ€è¦æ›´æ–°å®¢æˆ¶ç«¯

---

### æ–¹æ¡ˆ 2: è·¯ç”±å±¤ (Routing Tier)

**æ¶æ§‹**:

```mermaid
graph LR
    Client["å®¢æˆ¶ç«¯"] --> Router["è·¯ç”±å±¤<br/>(çŸ¥é“åˆ†å€æ˜ å°„)"]
    Router --> N1["ç¯€é» 1"]
    Router --> N2["ç¯€é» 2"]
    Router --> N3["ç¯€é» 3"]
```

**å¯¦ä½œç¯„ä¾‹**:

```python
from flask import Flask, request
import requests

app = Flask(__name__)
partitioner = ConsistentHash()
partitioner.add_node("http://node1:9000")
partitioner.add_node("http://node2:9000")
partitioner.add_node("http://node3:9000")

@app.route('/get/<key>')
def get_key(key):
    # è·¯ç”±å±¤è¨ˆç®—ç›®æ¨™ç¯€é»
    node = partitioner.get_node(key)
    response = requests.get(f"{node}/get/{key}")
    return response.json()

@app.route('/put/<key>', methods=['POST'])
def put_key(key):
    node = partitioner.get_node(key)
    response = requests.post(f"{node}/put/{key}", json=request.json)
    return response.json()

# å®¢æˆ¶ç«¯åªéœ€è¦çŸ¥é“è·¯ç”±å±¤åœ°å€
# curl http://router:8080/get/Alice
```

**ğŸ¢ çœŸå¯¦æ¡ˆä¾‹: MongoDB (mongos è·¯ç”±å™¨)**

**âœ… å„ªé»**: å®¢æˆ¶ç«¯ç°¡å–®,é›†ç¾¤è®Šæ›´å°å®¢æˆ¶ç«¯é€æ˜

**âŒ ç¼ºé»**: è·¯ç”±å±¤æˆç‚ºå–®é»æ•…éšœ (éœ€è¦é«˜å¯ç”¨éƒ¨ç½²)

---

### æ–¹æ¡ˆ 3: ç¯€é»å…§éƒ¨è½‰ç™¼

**æ¶æ§‹**:

```mermaid
graph LR
    Client["å®¢æˆ¶ç«¯"] -->|é€£æ¥ä»»æ„ç¯€é»| N1["ç¯€é» 1"]
    N1 -->|å…§éƒ¨è½‰ç™¼| N2["ç¯€é» 2<br/>(å¯¦éš›å­˜å„²)"]
    
    Client2["å®¢æˆ¶ç«¯"] -->|é€£æ¥ä»»æ„ç¯€é»| N3["ç¯€é» 3"]
    N3 -->|å…§éƒ¨è½‰ç™¼| N2
```

**å¯¦ä½œæ¦‚å¿µ**:

```python
class Node:
    def __init__(self, node_id, all_nodes):
        self.node_id = node_id
        self.all_nodes = all_nodes
        self.partitioner = ConsistentHash()
        for node in all_nodes:
            self.partitioner.add_node(node)
    
    def handle_request(self, key, operation):
        # è¨ˆç®—å¯¦éš›è² è²¬çš„ç¯€é»
        target_node = self.partitioner.get_node(key)
        
        if target_node == self.node_id:
            # æœ¬ç¯€é»è² è²¬,ç›´æ¥è™•ç†
            return self.local_handle(key, operation)
        else:
            # è½‰ç™¼åˆ°æ­£ç¢ºçš„ç¯€é»
            return self.forward_request(target_node, key, operation)

# å®¢æˆ¶ç«¯å¯ä»¥é€£æ¥ä»»æ„ç¯€é»
# ç¯€é»æœƒè‡ªå‹•è½‰ç™¼åˆ°æ­£ç¢ºä½ç½®
```

**ğŸ¢ çœŸå¯¦æ¡ˆä¾‹: Dynamo, Riak**

**âœ… å„ªé»**: å®¢æˆ¶ç«¯ç„¡éœ€çŸ¥é“é›†ç¾¤æ‹“æ’²

**âŒ ç¼ºé»**: å¤šä¸€æ¬¡ç¶²è·¯è·³è½‰

---

### å”èª¿æœå‹™ (Coordination Service)

**å•é¡Œ**: åˆ†å€æ˜ å°„åœ¨é›†ç¾¤è®Šæ›´æ™‚å¦‚ä½•åŒæ­¥?

**è§£æ±ºæ–¹æ¡ˆ: ä½¿ç”¨å”èª¿æœå‹™ (å¦‚ ZooKeeper, etcd)**

```mermaid
graph TD
    ZK["ZooKeeper<br/>(å­˜å„²åˆ†å€æ˜ å°„)"]
    
    N1["ç¯€é» 1"] -.->|è¨‚é–±è®Šæ›´| ZK
    N2["ç¯€é» 2"] -.->|è¨‚é–±è®Šæ›´| ZK
    N3["ç¯€é» 3"] -.->|è¨‚é–±è®Šæ›´| ZK
    
    Router["è·¯ç”±å±¤"] -.->|è¨‚é–±è®Šæ›´| ZK
    
    ZK -->|é€šçŸ¥è®Šæ›´| N1
    ZK -->|é€šçŸ¥è®Šæ›´| N2
    ZK -->|é€šçŸ¥è®Šæ›´| N3
    ZK -->|é€šçŸ¥è®Šæ›´| Router
```

**å¯¦ä½œç¯„ä¾‹ (ä½¿ç”¨ etcd)**:

```python
import etcd3

class PartitionRegistry:
    def __init__(self, etcd_host='localhost'):
        self.etcd = etcd3.client(host=etcd_host)
    
    def register_partition(self, partition_id, node_id):
        """è¨»å†Šåˆ†å€åˆ°ç¯€é»çš„æ˜ å°„"""
        key = f"/partitions/{partition_id}"
        self.etcd.put(key, node_id)
    
    def get_node(self, partition_id):
        """æŸ¥è©¢åˆ†å€å°æ‡‰çš„ç¯€é»"""
        key = f"/partitions/{partition_id}"
        value, _ = self.etcd.get(key)
        return value.decode() if value else None
    
    def watch_changes(self, callback):
        """ç›£è½åˆ†å€æ˜ å°„è®Šæ›´"""
        events, cancel = self.etcd.watch_prefix("/partitions/")
        for event in events:
            callback(event)

# ç¯€é»å•Ÿå‹•æ™‚è¨»å†Šåˆ†å€
registry = PartitionRegistry()
registry.register_partition(partition_id=1, node_id="node1")

# è·¯ç”±å±¤ç›£è½è®Šæ›´
def on_partition_change(event):
    print(f"åˆ†å€æ˜ å°„è®Šæ›´: {event}")

registry.watch_changes(on_partition_change)
```

**ğŸ¢ çœŸå¯¦æ¡ˆä¾‹**:
- **HBase**: ä½¿ç”¨ ZooKeeper è¿½è¹¤ Region Server
- **Kafka**: ä½¿ç”¨ ZooKeeper (èˆŠç‰ˆ) / KRaft (æ–°ç‰ˆ) ç®¡ç†åˆ†å€åˆ†é…
- **Elasticsearch**: ä½¿ç”¨å…§å»ºçš„é›†ç¾¤ç‹€æ…‹ç®¡ç†

---

## ğŸ¢ çœŸå¯¦ä¸–ç•Œæ¡ˆä¾‹ç ”ç©¶

### æ¡ˆä¾‹ 1: Cassandra åˆ†å€æ¶æ§‹

**åˆ†å€ç­–ç•¥**:
- **Murmur3 é›œæ¹Šåˆ†å€**
- **Token Ring**: é›œæ¹Šç©ºé–“ `0 - 2^64`

**æ¶æ§‹åœ–**:

```mermaid
graph TD
    subgraph TokenRing["Token Ring"]
        T1["Token: 0<br/>ç¯€é» A"]
        T2["Token: 2^62<br/>ç¯€é» B"]
        T3["Token: 2^63<br/>ç¯€é» C"]
        T4["Token: 3Ã—2^62<br/>ç¯€é» D"]
    end
    
    K1["Key: 'user123'<br/>Token: 1500"] -->|è½å…¥ç¯„åœ| T1
    K2["Key: 'user456'<br/>Token: 2^63+1000"] -->|è½å…¥ç¯„åœ| T3
```

**è¤‡è£½ç­–ç•¥**:
```sql
CREATE KEYSPACE my_keyspace
WITH replication = {
  'class': 'SimpleStrategy',
  'replication_factor': 3
};
```
- æ¯å€‹åˆ†å€è¤‡è£½åˆ° 3 å€‹é€£çºŒçš„ç¯€é»

**è®€å¯«æµç¨‹**:
```python
# å®¢æˆ¶ç«¯è¨ˆç®— Token
token = murmur3_hash('user123')

# æ‰¾åˆ°å”èª¿è€…ç¯€é» (Coordinator)
coordinator = find_node_by_token(token)

# å¯«å…¥ (è¤‡è£½å› å­ = 3)
coordinator.write(['node1', 'node2', 'node3'], data)

# è®€å– (æ³•å®šäººæ•¸ = 2)
values = coordinator.read(['node1', 'node2'], key)
```

---

### æ¡ˆä¾‹ 2: MongoDB åˆ†ç‰‡æ¶æ§‹

**çµ„ä»¶**:

```mermaid
graph TD
    App["æ‡‰ç”¨ç¨‹å¼"] --> Mongos["mongos<br/>(è·¯ç”±å±¤)"]
    
    Mongos --> CS["Config Server<br/>(å­˜å„²åˆ†ç‰‡æ˜ å°„)"]
    
    Mongos --> S1["Shard 1<br/>(Replica Set)"]
    Mongos --> S2["Shard 2<br/>(Replica Set)"]
    Mongos --> S3["Shard 3<br/>(Replica Set)"]
```

**åˆ†ç‰‡é…ç½®**:
```javascript
// å•Ÿç”¨åˆ†ç‰‡
sh.enableSharding("mydb")

// é¸æ“‡åˆ†ç‰‡éµ
sh.shardCollection("mydb.users", { "userId": 1 })

// MongoDB è‡ªå‹•åˆ†é…è³‡æ–™åˆ°å„åˆ†ç‰‡
```

**åˆ†ç‰‡éµé¸æ“‡åŸå‰‡**:
1. **é«˜åŸºæ•¸ (High Cardinality)**: éµå€¼å¤šæ¨£åŒ–
2. **ä½é »ç‡ (Low Frequency)**: é¿å…å¤§é‡æ–‡ä»¶æœ‰ç›¸åŒéµå€¼
3. **éå–®èª¿ (Non-Monotonic)**: é¿å…ç†±é»

**éŒ¯èª¤ç¤ºä¾‹**:
```javascript
// âŒ ä½¿ç”¨è‡ªå¢ ID (å–®èª¿å¢é•·,é€ æˆç†±é»)
sh.shardCollection("mydb.orders", { "_id": 1 })

// âœ… ä½¿ç”¨è¤‡åˆéµ
sh.shardCollection("mydb.orders", { "userId": 1, "timestamp": 1 })
```

---

### æ¡ˆä¾‹ 3: Amazon DynamoDB åˆ†å€

**åˆ†å€ç­–ç•¥**:
- **ä¸€è‡´æ€§é›œæ¹Š + è™›æ“¬ç¯€é»**
- è‡ªå‹•é‡å¹³è¡¡

**åˆ†å€éµ (Partition Key) + æ’åºéµ (Sort Key)**:

```python
# è¡¨å®šç¾©
table = dynamodb.Table('Orders')

# åˆ†å€éµ: 'userId'
# æ’åºéµ: 'timestamp'

# å¯«å…¥
table.put_item(
    Item={
        'userId': 'user123',  # æ±ºå®šåˆ†å€
        'timestamp': 1704067200,  # åˆ†å€å…§æ’åº
        'orderId': 'order_456',
        'amount': 99.99
    }
)

# æŸ¥è©¢ (é«˜æ•ˆ: åªæƒæä¸€å€‹åˆ†å€)
response = table.query(
    KeyConditionExpression=Key('userId').eq('user123') &
                           Key('timestamp').between(start, end)
)
```

**è‡ªå‹•æ“´å±•**:
- åˆ†å€å¤§å°é” 10GB æ™‚è‡ªå‹•åˆ†è£‚
- è®€å¯«ååé‡ä¸è¶³æ™‚è‡ªå‹•å¢åŠ åˆ†å€

**ç†±é»è™•ç†**:
- **è‡ªé©æ‡‰å®¹é‡ (Adaptive Capacity)**: è‡ªå‹•å°‡æ›´å¤šè³‡æºåˆ†é…çµ¦ç†±åˆ†å€

---

## ğŸ¤” æ·±å…¥æ€è€ƒ

### ç·´ç¿’ 1: è¨­è¨ˆåˆ†å€æ–¹æ¡ˆ

**å ´æ™¯**: è¨­è¨ˆä¸€å€‹ Twitter é¢¨æ ¼çš„ç¤¾äº¤åª’é«”è³‡æ–™åº«

**éœ€æ±‚**:
- 10 å„„ä½¿ç”¨è€…
- æ¯å€‹ä½¿ç”¨è€…å¹³å‡ 1000 æ¢æ¨æ–‡
- æŸ¥è©¢é¡å‹:
  1. æ ¹æ“šä½¿ç”¨è€… ID æŸ¥è©¢æ¨æ–‡
  2. æ ¹æ“šæ™‚é–“ç¯„åœæŸ¥è©¢æ¨æ–‡
  3. ç†±é–€æ¨æ–‡æ’è¡Œ

**å•é¡Œ**:
1. é¸æ“‡ä»€éº¼åˆ†å€éµ?
2. å¦‚ä½•é¿å…åäººè³¬è™Ÿçš„ç†±é»?
3. å¦‚ä½•æ”¯æŒæ™‚é–“ç¯„åœæŸ¥è©¢?

<details>
<summary>ğŸ’¡ åƒè€ƒç­”æ¡ˆ</summary>

**æ–¹æ¡ˆ 1: æŒ‰ä½¿ç”¨è€… ID åˆ†å€**

```python
# åˆ†å€éµ: user_id
partition = hash(user_id) % num_partitions

# âœ… å„ªé»:
# - æŸ¥è©¢æŸä½¿ç”¨è€…çš„æ¨æ–‡é«˜æ•ˆ (å–®åˆ†å€)
# - å¯«å…¥æ¨æ–‡å‡å‹»åˆ†å¸ƒ

# âŒ ç¼ºé»:
# - åäººè³¬è™Ÿç†±é»
# - æ™‚é–“ç¯„åœæŸ¥è©¢éœ€è¦æƒææ‰€æœ‰åˆ†å€
```

**ç†±é»è§£æ±º**: åäººè³¬è™Ÿä½¿ç”¨éµåˆ†è£‚
```python
if is_celebrity(user_id):
    # åˆ†è£‚æˆ 10 å€‹å­éµ
    replica_id = random.randint(0, 9)
    partition = hash(f"{user_id}_{replica_id}") % num_partitions
```

**æ–¹æ¡ˆ 2: æŒ‰æ™‚é–“åˆ†å€ (è¼”åŠ©ç´¢å¼•)**

```python
# ä¸»è¡¨: æŒ‰ user_id åˆ†å€
tweets_by_user = {
    partition_key: user_id,
    sort_key: timestamp,
    data: tweet_content
}

# äºŒç´šç´¢å¼•: æŒ‰æ™‚é–“åˆ†å€
tweets_by_time = {
    partition_key: date,
    sort_key: timestamp,
    data: tweet_id
}
```

**æ–¹æ¡ˆ 3: è¤‡åˆåˆ†å€éµ**

```python
# çµåˆ user_id å’Œæ—¥æœŸ
composite_key = f"{user_id}_{date}"
partition = hash(composite_key) % num_partitions

# âœ… æ”¯æŒæŸ¥è©¢ç‰¹å®šä½¿ç”¨è€…åœ¨ç‰¹å®šæ—¥æœŸçš„æ¨æ–‡
# âŒ è·¨æ—¥æœŸæŸ¥è©¢éœ€è¦å¤šå€‹è«‹æ±‚
```

</details>

---

### ç·´ç¿’ 2: åˆ†æåˆ†å€é‡å¹³è¡¡

**å ´æ™¯**: é›»å•†ç¶²ç«™ä½¿ç”¨é›œæ¹Šåˆ†å€,4 å€‹ç¯€é»å­˜å„²å•†å“è³‡æ–™ã€‚

**åˆå§‹ç‹€æ…‹**:
- ç¯€é» A, B, C, D
- æ¯å€‹ç¯€é» 100GB è³‡æ–™
- åˆ†å€ç­–ç•¥: `hash(product_id) % 4`

**æ“ä½œ**: æ·»åŠ ç¯€é» E,è®Šæˆ 5 å€‹ç¯€é»

**å•é¡Œ**:
1. ä½¿ç”¨ç°¡å–®å–æ¨¡ `% 5`,æœ‰å¤šå°‘æ¯”ä¾‹çš„éµéœ€è¦é·ç§»?
2. ä½¿ç”¨ä¸€è‡´æ€§é›œæ¹Š,éœ€è¦é·ç§»å¤šå°‘éµ?
3. å“ªç¨®æ–¹æ¡ˆæ›´é©åˆé »ç¹æ“´å±•çš„å ´æ™¯?

<details>
<summary>ğŸ’¡ åƒè€ƒç­”æ¡ˆ</summary>

**1. ç°¡å–®å–æ¨¡é·ç§»æ¯”ä¾‹**:

```python
# æ¨¡æ“¬åˆ†æ
num_keys = 100000
old_partitions = 4
new_partitions = 5

changed = 0
for key in range(num_keys):
    old_partition = key % old_partitions
    new_partition = key % new_partitions
    if old_partition != new_partition:
        changed += 1

print(f"éœ€è¦é·ç§»: {changed / num_keys * 100:.1f}%")
# è¼¸å‡º: ç´„ 80% çš„éµéœ€è¦é·ç§»!
```

**2. ä¸€è‡´æ€§é›œæ¹Šé·ç§»æ¯”ä¾‹**:

ç†è«–ä¸Š:
```
é·ç§»æ¯”ä¾‹ = 1 / (n_new) = 1 / 5 = 20%
```

**3. æ–¹æ¡ˆå°æ¯”**:

| æ–¹æ¡ˆ | é·ç§»æ¯”ä¾‹ | å¯¦ä½œè¤‡é›œåº¦ | é©ç”¨å ´æ™¯ |
|------|---------|-----------|----------|
| ç°¡å–®å–æ¨¡ | ~80% | ç°¡å–® | ç¯€é»æ•¸å›ºå®š |
| ä¸€è‡´æ€§é›œæ¹Š | ~20% | ä¸­ç­‰ | é »ç¹æ“´å±• |
| å›ºå®šåˆ†å€ | ~20% | ç°¡å–® | é å…ˆè¦åŠƒ |

**çµè«–**: é »ç¹æ“´å±•æ‡‰ä½¿ç”¨ä¸€è‡´æ€§é›œæ¹Šæˆ–å›ºå®šåˆ†å€æ•¸ã€‚

</details>

---

## ğŸ“š ç¸½çµ

### æ ¸å¿ƒè¦é»

```mermaid
graph TD
    A["è³‡æ–™åˆ†å€"] --> B["åˆ†å€ç­–ç•¥"]
    A --> C["ç†±é»è™•ç†"]
    A --> D["é‡å¹³è¡¡"]
    A --> E["è·¯ç”±æ©Ÿåˆ¶"]
    
    B --> B1["ç¯„åœåˆ†å€: æ”¯æŒç¯„åœæŸ¥è©¢"]
    B --> B2["é›œæ¹Šåˆ†å€: è² è¼‰å‡å‹»"]
    B --> B3["ä¸€è‡´æ€§é›œæ¹Š: æ˜“æ–¼æ“´å±•"]
    
    C --> C1["éµåˆ†è£‚"]
    C --> C2["è¤‡åˆåˆ†å€éµ"]
    
    D --> D1["å›ºå®šåˆ†å€æ•¸"]
    D --> D2["å‹•æ…‹åˆ†è£‚"]
    D --> D3["æŒ‰ç¯€é»æ¯”ä¾‹"]
    
    E --> E1["å®¢æˆ¶ç«¯è·¯ç”±"]
    E --> E2["è·¯ç”±å±¤"]
    E --> E3["ç¯€é»è½‰ç™¼"]
```

### æ±ºç­–æŒ‡å—

**é¸æ“‡åˆ†å€ç­–ç•¥**:

```mermaid
graph TD
    A{"éœ€è¦ç¯„åœæŸ¥è©¢?"} -->|æ˜¯| B["ç¯„åœåˆ†å€"]
    A -->|å¦| C{"è³‡æ–™åˆ†å¸ƒå‡å‹»?"}
    C -->|æ˜¯| D["é›œæ¹Šåˆ†å€"]
    C -->|å¦| E["ä¸€è‡´æ€§é›œæ¹Š"]
    
    B --> B1["æ³¨æ„ç†±é»å•é¡Œ"]
    D --> D1["é‡å¹³è¡¡æˆæœ¬é«˜"]
    E --> E1["é©åˆå‹•æ…‹æ“´å±•"]
```

**é¿å…å¸¸è¦‹é™·é˜±**:

| å•é¡Œ | ç—‡ç‹€ | è§£æ±ºæ–¹æ¡ˆ |
|------|------|----------|
| **ç†±é»** | å–®å€‹åˆ†å€è² è¼‰éé«˜ | éµåˆ†è£‚ã€è¤‡åˆåˆ†å€éµ |
| **ä¸å‡å‹»åˆ†å¸ƒ** | æŸäº›åˆ†å€é å¤§æ–¼å…¶ä»– | é›œæ¹Šåˆ†å€ã€å‹•æ…‹åˆ†è£‚ |
| **é‡å¹³è¡¡é¢¨æš´** | æ·»åŠ ç¯€é»å°è‡´å¤§é‡é·ç§» | ä¸€è‡´æ€§é›œæ¹Šã€å›ºå®šåˆ†å€æ•¸ |
| **ç„¡æ³•ç¯„åœæŸ¥è©¢** | é›œæ¹Šæ‰“äº‚é †åº | ä½¿ç”¨ç¯„åœåˆ†å€æˆ–äºŒç´šç´¢å¼• |

### æœ€ä½³å¯¦è¸

1. **åˆ†å€éµé¸æ“‡**:
   - é«˜åŸºæ•¸ (Cardinality)
   - å‡å‹»åˆ†å¸ƒ
   - èˆ‡æŸ¥è©¢æ¨¡å¼åŒ¹é…

2. **ç›£æ§æŒ‡æ¨™**:
   - æ¯å€‹åˆ†å€çš„å¤§å°
   - æ¯å€‹åˆ†å€çš„ QPS
   - åˆ†å€é–“çš„ä¸å¹³è¡¡ç¨‹åº¦

3. **æ¸¬è©¦**:
   - æ¨¡æ“¬ç†±é»å ´æ™¯
   - æ¸¬è©¦é‡å¹³è¡¡æ“ä½œ
   - é©—è­‰æ•…éšœæ¢å¾©

---

## ğŸ”— åƒè€ƒè³‡æ–™

1. **æ›¸ç±**:
   - Martin Kleppmann, *Designing Data-Intensive Applications*, Chapter 6
   - Alex Petrov, *Database Internals*

2. **è«–æ–‡**:
   - [Consistent Hashing and Random Trees](https://www.akamai.com/us/en/multimedia/documents/technical-publication/consistent-hashing-and-random-trees-distributed-caching-protocols-for-relieving-hot-spots-on-the-world-wide-web-technical-publication.pdf)
   - [Dynamo: Amazon's Highly Available Key-value Store](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)

3. **æŠ€è¡“æ–‡ä»¶**:
   - [Cassandra Architecture](https://cassandra.apache.org/doc/latest/architecture/dynamo.html)
   - [MongoDB Sharding](https://docs.mongodb.com/manual/sharding/)
   - [HBase Region Splitting](https://hbase.apache.org/book.html#regions.arch)

4. **éƒ¨è½æ ¼**:
   - [Sharding Pinterest: How we scaled our MySQL fleet](https://medium.com/pinterest-engineering/sharding-pinterest-how-we-scaled-our-mysql-fleet-3f341e96ca6f)
   - [How Discord Stores Billions of Messages](https://discord.com/blog/how-discord-stores-billions-of-messages)
