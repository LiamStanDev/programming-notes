# 02-æ ¸å¿ƒæ¦‚å¿µèˆ‡æ¶æ§‹

> æ·±å…¥ç†è§£ Kubernetes çš„è¨­è¨ˆåŸç†èˆ‡æ ¸å¿ƒçµ„ä»¶

---

## ğŸ“š æœ¬ç« ç›®æ¨™

- æŒæ¡ Kubernetes çš„æ¶æ§‹è¨­è¨ˆ
- ç†è§£æ§åˆ¶å¹³é¢èˆ‡æ•¸æ“šå¹³é¢çš„è·è²¬
- æ·±å…¥å­¸ç¿’æ ¸å¿ƒ API ç‰©ä»¶
- æŒæ¡é–‹ç™¼è€…è¦–è§’çš„æ’æŸ¥æ–¹æ³•

---

## 1. Kubernetes æ¶æ§‹ç¸½è¦½

### 1.1 æ•´é«”æ¶æ§‹åœ–

```mermaid
graph TB
    subgraph "Control Plane æ§åˆ¶å¹³é¢"
        API[API Server<br/>çµ±ä¸€å…¥å£]
        ETCD[etcd<br/>ç‹€æ…‹å„²å­˜]
        Scheduler[Scheduler<br/>èª¿åº¦å™¨]
        Controller[Controller Manager<br/>æ§åˆ¶å™¨]
        CCM[Cloud Controller<br/>é›²æœå‹™æ•´åˆ]
    end
    
    subgraph "Node 1 å·¥ä½œç¯€é»"
        Kubelet1[Kubelet<br/>ç¯€é»ä»£ç†]
        Proxy1[kube-proxy<br/>ç¶²è·¯ä»£ç†]
        Runtime1[Container Runtime<br/>å®¹å™¨é‹è¡Œæ™‚]
        Pod1[Pods]
    end
    
    subgraph "Node 2 å·¥ä½œç¯€é»"
        Kubelet2[Kubelet]
        Proxy2[kube-proxy]
        Runtime2[Container Runtime]
        Pod2[Pods]
    end
    
    User[é–‹ç™¼è€…/kubectl] --> API
    API <--> ETCD
    API --> Scheduler
    API --> Controller
    API --> CCM
    
    Kubelet1 --> API
    Kubelet2 --> API
    
    Kubelet1 --> Runtime1
    Runtime1 --> Pod1
    Kubelet2 --> Runtime2
    Runtime2 --> Pod2
    
    Proxy1 -.ç¶²è·¯è¦å‰‡.-> Pod1
    Proxy2 -.ç¶²è·¯è¦å‰‡.-> Pod2
    
    style API fill:#9cf
    style ETCD fill:#fc9
    style Pod1 fill:#9f9
    style Pod2 fill:#9f9
```

### 1.2 è¨­è¨ˆç†å¿µ

**æ ¸å¿ƒåŸå‰‡ï¼š**
- **è²æ˜å¼ API**ï¼šç”¨æˆ¶è²æ˜æœŸæœ›ç‹€æ…‹ï¼Œç³»çµ±è‡ªå‹•èª¿å’Œï¼ˆReconciliationï¼‰
- **æ§åˆ¶è¿´è·¯**ï¼šæŒçºŒç›£æ§å¯¦éš›ç‹€æ…‹ï¼Œç¢ºä¿èˆ‡æœŸæœ›ç‹€æ…‹ä¸€è‡´
- **é¬†è€¦åˆ**ï¼šå„çµ„ä»¶ç¨ç«‹é‹ä½œï¼Œé€šé API Server é€šè¨Š
- **å¯æ“´å±•æ€§**ï¼šæ”¯æŒ CRDï¼ˆCustom Resource Definitionï¼‰è‡ªå®šç¾©è³‡æº

```mermaid
flowchart LR
    A[ç”¨æˆ¶è²æ˜<br/>æœŸæœ›ç‹€æ…‹] --> B[API Server]
    B --> C[etcd å„²å­˜]
    C --> D[Controller ç›£æ§]
    D --> E{å¯¦éš› = æœŸæœ›?}
    E -->|å¦| F[åŸ·è¡Œèª¿å’Œå‹•ä½œ]
    F --> G[æ›´æ–°å¯¦éš›ç‹€æ…‹]
    G --> D
    E -->|æ˜¯| H[æŒçºŒç›£æ§]
    H --> D
    
    style A fill:#9cf
    style E fill:#fc9
    style F fill:#f96
```

---

## 2. æ§åˆ¶å¹³é¢çµ„ä»¶è©³è§£

### 2.1 API Server

**è·è²¬ï¼š**
- Kubernetes çš„ã€Œå¤§è…¦ã€ï¼Œæ‰€æœ‰æ“ä½œçš„çµ±ä¸€å…¥å£
- æä¾› RESTful API ä»‹é¢
- è™•ç†èªè­‰ã€æˆæ¬Šã€é©—è­‰
- å”¯ä¸€èˆ‡ etcd é€šè¨Šçš„çµ„ä»¶

```mermaid
sequenceDiagram
    participant User as é–‹ç™¼è€…
    participant kubectl
    participant API as API Server
    participant etcd
    participant Controller
    
    User->>kubectl: kubectl apply -f app.yaml
    kubectl->>API: POST /apis/apps/v1/deployments
    API->>API: èªè­‰ & æˆæ¬Š
    API->>API: é©—è­‰ YAML æ ¼å¼
    API->>etcd: å„²å­˜æœŸæœ›ç‹€æ…‹
    etcd-->>API: ç¢ºèªå„²å­˜
    API-->>kubectl: 201 Created
    kubectl-->>User: deployment created
    
    Controller->>API: Watch deployments
    API-->>Controller: Notify change
    Controller->>Controller: èª¿å’Œå‹•ä½œ
```

**é–‹ç™¼è€…äº¤äº’ï¼š**
```bash
kubectl get pods --v=9
```
æŸ¥çœ‹ kubectl èˆ‡ API Server çš„å®Œæ•´äº¤äº’éç¨‹ã€‚

### 2.2 etcd

**è·è²¬ï¼š**
- åˆ†æ•£å¼éµå€¼å„²å­˜ï¼Œä¿å­˜é›†ç¾¤æ‰€æœ‰ç‹€æ…‹æ•¸æ“š
- æä¾› Watch æ©Ÿåˆ¶ï¼Œæ”¯æŒäº‹ä»¶é€šçŸ¥
- æ”¯æŒå¿«ç…§èˆ‡å‚™ä»½

```mermaid
graph TB
    subgraph "etcd å„²å­˜å…§å®¹"
        A[Deployments]
        B[Services]
        C[Pods]
        D[ConfigMaps]
        E[Secrets]
        F[...æ‰€æœ‰ API ç‰©ä»¶]
    end
    
    API[API Server] <--> A
    API <--> B
    API <--> C
    API <--> D
    API <--> E
    API <--> F
    
    style API fill:#9cf
    style A fill:#fc9
    style B fill:#fc9
    style C fill:#fc9
```

**é‡è¦æ€§ï¼š**
- etcd æ˜¯é›†ç¾¤çš„ã€ŒçœŸå¯¦ä¾†æºã€ï¼ˆSingle Source of Truthï¼‰
- etcd æ•…éšœ = é›†ç¾¤ç„¡æ³•é‹ä½œï¼ˆéœ€é«˜å¯ç”¨é…ç½®ï¼‰

**é–‹ç™¼è€…å½±éŸ¿ï¼š**
- å¤§é‡é »ç¹å‰µå»º/åˆªé™¤è³‡æºæœƒå¢åŠ  etcd å£“åŠ›
- å¤§å‹ ConfigMap/Secret æœƒä½”ç”¨ etcd ç©ºé–“ï¼ˆå»ºè­° < 1MBï¼‰

### 2.3 Scheduler

**è·è²¬ï¼š**
- ç‚ºæ–°å‰µå»ºçš„ Pod é¸æ“‡åˆé©çš„ Node
- è€ƒæ…®è³‡æºéœ€æ±‚ã€è¦ªå’Œæ€§ã€æ±¡é»èˆ‡å®¹å¿ç­‰

```mermaid
flowchart TD
    A[æ–° Pod å‰µå»º] --> B[Scheduler æª¢æ¸¬]
    B --> C{éæ¿¾å¯ç”¨ Node}
    C --> D[Node 1<br/>è³‡æºå……è¶³]
    C --> E[Node 2<br/>è³‡æºä¸è¶³]
    C --> F[Node 3<br/>æœ‰æ±¡é»]
    
    E -.æ’é™¤.-> G[è©•åˆ†éšæ®µ]
    F -.æ’é™¤.-> G
    D --> G
    
    G --> H[é¸æ“‡æœ€å„ª Node]
    H --> I[ç¶å®š Pod åˆ° Node]
    
    style E fill:#f96
    style F fill:#f96
    style H fill:#9f9
```

**èª¿åº¦éç¨‹ï¼š**

1. **éæ¿¾éšæ®µï¼ˆFilteringï¼‰ï¼š**
   - è³‡æºæ˜¯å¦å……è¶³ï¼ˆCPUã€Memoryï¼‰
   - æ˜¯å¦æ»¿è¶³è¦ªå’Œæ€§è¦å‰‡
   - æ˜¯å¦å®¹å¿ Node æ±¡é»

2. **è©•åˆ†éšæ®µï¼ˆScoringï¼‰ï¼š**
   - è³‡æºå¹³è¡¡åº¦
   - è¦ªå’Œæ€§æ¬Šé‡
   - è‡ªå®šç¾©è©•åˆ†ç­–ç•¥

**é–‹ç™¼è€…å¸¸è¦‹å•é¡Œï¼š**

| ç‹€æ…‹ | åŸå›  | è§£æ±ºæ–¹æ³• |
|-----|------|---------|
| **Pending** | æ²’æœ‰å¯ç”¨ Node | æª¢æŸ¥è³‡æºè«‹æ±‚æ˜¯å¦éå¤§ |
| **Pending** | ä¸æ»¿è¶³è¦ªå’Œæ€§ | æª¢æŸ¥ `nodeSelector` æˆ– `affinity` |
| **Pending** | ç„¡æ³•å®¹å¿æ±¡é» | æ·»åŠ  `tolerations` |

```bash
kubectl describe pod <pod-name>
```
æŸ¥çœ‹èª¿åº¦å¤±æ•—åŸå› ã€‚

### 2.4 Controller Manager

**è·è²¬ï¼š**
- é‹è¡Œå„ç¨®æ§åˆ¶å™¨ï¼ˆControllerï¼‰
- æŒçºŒç›£æ§è³‡æºç‹€æ…‹ï¼ŒåŸ·è¡Œèª¿å’Œé‚è¼¯

```mermaid
graph TB
    subgraph "Controller Manager"
        DC[Deployment Controller]
        RC[ReplicaSet Controller]
        NC[Node Controller]
        SC[Service Controller]
        EC[Endpoint Controller]
        More[...]
    end
    
    DC -->|ç›£æ§| API[API Server]
    RC -->|ç›£æ§| API
    NC -->|ç›£æ§| API
    SC -->|ç›£æ§| API
    EC -->|ç›£æ§| API
    
    API -->|é€šçŸ¥è®Šæ›´| DC
    API -->|é€šçŸ¥è®Šæ›´| RC
    
    style DC fill:#9cf
    style RC fill:#9cf
```

**å¸¸è¦‹ Controllerï¼š**

| Controller | è·è²¬ |
|-----------|------|
| **Deployment Controller** | ç®¡ç† ReplicaSetï¼Œå¯¦ç¾æ»¾å‹•æ›´æ–° |
| **ReplicaSet Controller** | ç¢ºä¿ Pod å‰¯æœ¬æ•¸ç¬¦åˆæœŸæœ› |
| **Node Controller** | ç›£æ§ Node å¥åº·ç‹€æ…‹ |
| **Service Controller** | é…ç½® LoadBalancer |
| **Endpoint Controller** | æ›´æ–° Service çš„ Endpoint åˆ—è¡¨ |

**æ§åˆ¶å™¨å·¥ä½œåŸç†ï¼š**

```mermaid
flowchart LR
    A[Watch API Server] --> B[æª¢æ¸¬è®Šæ›´äº‹ä»¶]
    B --> C{å¯¦éš› = æœŸæœ›?}
    C -->|æ˜¯| A
    C -->|å¦| D[è¨ˆç®—å·®ç•°]
    D --> E[åŸ·è¡Œèª¿å’Œå‹•ä½œ]
    E --> F[æ›´æ–°ç‹€æ…‹]
    F --> A
    
    style C fill:#fc9
    style E fill:#9f9
```

---

## 3. å·¥ä½œç¯€é»çµ„ä»¶è©³è§£

### 3.1 Kubelet

**è·è²¬ï¼š**
- ç¯€é»ä¸Šçš„ã€Œç®¡å®¶ã€ï¼Œè² è²¬ Pod ç”Ÿå‘½é€±æœŸç®¡ç†
- èˆ‡ API Server é€šè¨Šï¼Œæ¥æ”¶ Pod é…ç½®
- èª¿ç”¨ Container Runtime å‰µå»ºå®¹å™¨
- ç›£æ§ Pod å¥åº·ç‹€æ…‹ï¼ŒåŸ·è¡Œå¥åº·æª¢æŸ¥

```mermaid
sequenceDiagram
    participant API as API Server
    participant Kubelet
    participant Runtime as Container Runtime
    participant Container
    
    API->>Kubelet: èª¿åº¦ Pod åˆ°æ­¤ Node
    Kubelet->>Kubelet: æª¢æŸ¥ Pod è¦æ ¼
    Kubelet->>Runtime: æ‹‰å–é¡åƒ
    Runtime->>Runtime: Pull image
    Kubelet->>Runtime: å‰µå»ºå®¹å™¨
    Runtime->>Container: Start container
    Container-->>Runtime: Running
    Runtime-->>Kubelet: Container started
    Kubelet->>Container: åŸ·è¡Œå¥åº·æª¢æŸ¥
    Container-->>Kubelet: Health check OK
    Kubelet->>API: æ›´æ–° Pod ç‹€æ…‹
```

**Kubelet ç®¡ç†çš„å…§å®¹ï¼š**
- **Pod ç”Ÿå‘½é€±æœŸ**ï¼šå‰µå»ºã€å•Ÿå‹•ã€åœæ­¢ã€åˆªé™¤
- **Volume æ›è¼‰**ï¼šæº–å‚™ä¸¦æ›è¼‰å­˜å„²å·
- **å¥åº·æª¢æŸ¥**ï¼šåŸ·è¡Œ liveness/readiness probe
- **è³‡æºç›£æ§**ï¼šæ”¶é›† CPUã€Memory ä½¿ç”¨æƒ…æ³

### 3.2 Container Runtime

**æ”¯æŒçš„é‹è¡Œæ™‚ï¼š**
- **containerd**ï¼ˆæ¨è–¦ï¼‰ï¼šè¼•é‡ã€é«˜æ•ˆ
- **CRI-O**ï¼šå°ˆç‚º Kubernetes è¨­è¨ˆ
- **Docker**ï¼ˆé€é cri-dockerdï¼‰ï¼šéœ€é¡å¤–çµ„ä»¶

```mermaid
graph LR
    Kubelet[Kubelet] -->|CRI ä»‹é¢| Runtime[Container Runtime]
    Runtime --> containerd
    Runtime --> CRI-O
    Runtime --> Docker+shim[Docker + cri-dockerd]
    
    containerd --> runc[runc]
    CRI-O --> runc
    Docker+shim --> runc
    
    style Runtime fill:#9cf
    style runc fill:#fc9
```

**CRIï¼ˆContainer Runtime Interfaceï¼‰ï¼š**
- Kubernetes èˆ‡å®¹å™¨é‹è¡Œæ™‚çš„æ¨™æº–ä»‹é¢
- æ”¯æŒå¤šç¨®é‹è¡Œæ™‚å¯¦ç¾

### 3.3 kube-proxy

**è·è²¬ï¼š**
- ç¶­è­·ç¯€é»ä¸Šçš„ç¶²è·¯è¦å‰‡
- å¯¦ç¾ Service çš„è² è¼‰å‡è¡¡
- æ”¯æŒå¤šç¨®æ¨¡å¼ï¼šiptablesã€ipvsã€userspace

```mermaid
graph TB
    subgraph "Node"
        A[kube-proxy] -->|é…ç½®| B[iptables è¦å‰‡]
        A -->|æˆ–é…ç½®| C[IPVS è¦å‰‡]
        
        B --> D[DNAT è½‰æ›]
        C --> D
        
        D --> E[Pod 1:80]
        D --> F[Pod 2:80]
        D --> G[Pod 3:80]
    end
    
    Client[å®¢æˆ¶ç«¯è«‹æ±‚<br/>Service IP:80] --> D
    
    style A fill:#9cf
    style D fill:#fc9
```

**å·¥ä½œæ¨¡å¼å°æ¯”ï¼š**

| æ¨¡å¼ | å„ªé» | ç¼ºé» |
|-----|------|------|
| **iptables** | æˆç†Ÿç©©å®š | è¦å‰‡å¤šæ™‚æ€§èƒ½ä¸‹é™ |
| **ipvs** | é«˜æ€§èƒ½ã€å¤šç¨®è² è¼‰å‡è¡¡ç®—æ³• | éœ€å…§æ ¸æ”¯æŒ |
| **userspace** | æœ€æ—©æ¨¡å¼ | æ€§èƒ½å·®ï¼Œå·²æ£„ç”¨ |

---

## 4. æ ¸å¿ƒ API ç‰©ä»¶æ·±åº¦è§£æ

### 4.1 Pod

**Pod æ˜¯ä»€éº¼ï¼š**
- Kubernetes æœ€å°èª¿åº¦å–®ä½
- åŒ…å«ä¸€å€‹æˆ–å¤šå€‹å®¹å™¨
- å…±äº«ç¶²çµ¡å‘½åç©ºé–“ã€IPCã€UTS

```mermaid
graph TB
    subgraph "Pod"
        subgraph "Network Namespace"
            C1[Container 1<br/>App]
            C2[Container 2<br/>Sidecar]
        end
        
        C1 -.å…±äº« localhost.-> C2
        
        V1[Volume 1<br/>å…±äº«å­˜å„²]
        V2[Volume 2<br/>æ—¥èªŒç›®éŒ„]
        
        C1 --> V1
        C1 --> V2
        C2 --> V2
    end
    
    style C1 fill:#9cf
    style C2 fill:#fc9
```

**å®Œæ•´ Pod é…ç½®ç¤ºä¾‹ï¼š**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: webapp
  labels:
    app: webapp
    tier: frontend
spec:
  initContainers:
  - name: init-db
    image: busybox:1.36
    command: ['sh', '-c', 'until nc -z db 5432; do sleep 1; done']
  
  containers:
  - name: app
    image: myapp:v1.0
    ports:
    - containerPort: 8080
      name: http
    
    env:
    - name: DB_HOST
      value: "db.default.svc.cluster.local"
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: password
    
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 512Mi
    
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10
    
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
    
    volumeMounts:
    - name: config
      mountPath: /etc/config
    - name: data
      mountPath: /data
  
  - name: log-sidecar
    image: fluentd:v1.16
    volumeMounts:
    - name: data
      mountPath: /data
      readOnly: true
  
  volumes:
  - name: config
    configMap:
      name: app-config
  - name: data
    emptyDir: {}
  
  restartPolicy: Always
  
  nodeSelector:
    disktype: ssd
  
  tolerations:
  - key: "workload"
    operator: "Equal"
    value: "frontend"
    effect: "NoSchedule"
```

**Pod ç”Ÿå‘½é€±æœŸï¼š**

```mermaid
stateDiagram-v2
    [*] --> Pending: Pod å‰µå»º
    Pending --> Running: å®¹å™¨å•Ÿå‹•
    Running --> Succeeded: æ­£å¸¸çµæŸ
    Running --> Failed: ç•°å¸¸é€€å‡º
    Running --> Unknown: Node å¤±è¯
    Failed --> Running: restartPolicy=Always
    
    Succeeded --> [*]
    Failed --> [*]: restartPolicy=Never
    
    note right of Pending
        ç­‰å¾…èª¿åº¦
        æ‹‰å–é¡åƒ
    end note
    
    note right of Running
        åŸ·è¡Œå¥åº·æª¢æŸ¥
        è™•ç†è«‹æ±‚
    end note
```

**Pod éšæ®µèªªæ˜ï¼š**

| éšæ®µ | èªªæ˜ | å¸¸è¦‹åŸå›  |
|-----|------|---------|
| **Pending** | ç­‰å¾…èª¿åº¦æˆ–å•Ÿå‹• | è³‡æºä¸è¶³ã€é¡åƒæ‹‰å–ä¸­ |
| **Running** | è‡³å°‘ä¸€å€‹å®¹å™¨é‹è¡Œä¸­ | æ­£å¸¸ç‹€æ…‹ |
| **Succeeded** | æ‰€æœ‰å®¹å™¨æˆåŠŸçµæŸ | Job/CronJob å®Œæˆ |
| **Failed** | æ‰€æœ‰å®¹å™¨çµæŸï¼Œè‡³å°‘ä¸€å€‹å¤±æ•— | æ‡‰ç”¨éŒ¯èª¤ |
| **Unknown** | ç„¡æ³•ç²å–ç‹€æ…‹ | Node å¤±è¯ |

### 4.2 Deployment

**Deployment ç®¡ç†å±¤ç´šï¼š**

```mermaid
graph TB
    D[Deployment<br/>nginx-demo] --> RS1[ReplicaSet<br/>nginx-demo-v1]
    D --> RS2[ReplicaSet<br/>nginx-demo-v2]
    
    RS1 -.èˆŠç‰ˆæœ¬.-> P1[Pod v1]
    RS1 -.èˆŠç‰ˆæœ¬.-> P2[Pod v1]
    
    RS2 --> P3[Pod v2]
    RS2 --> P4[Pod v2]
    RS2 --> P5[Pod v2]
    
    style D fill:#9cf
    style RS2 fill:#9f9
    style RS1 fill:#ccc
```

**æ»¾å‹•æ›´æ–°æµç¨‹ï¼š**

```mermaid
sequenceDiagram
    participant User
    participant Deployment
    participant RS_Old as ReplicaSet v1
    participant RS_New as ReplicaSet v2
    participant Pods
    
    User->>Deployment: æ›´æ–°é¡åƒç‰ˆæœ¬
    Deployment->>RS_New: å‰µå»ºæ–° ReplicaSet
    
    loop æ»¾å‹•æ›´æ–°
        RS_New->>Pods: å‰µå»º 1 å€‹æ–° Pod
        Pods-->>RS_New: Pod Ready
        RS_Old->>Pods: åˆªé™¤ 1 å€‹èˆŠ Pod
    end
    
    Deployment->>RS_Old: ç¸®æ¸›å‰¯æœ¬è‡³ 0
    
    Note over Deployment: ä¿ç•™èˆŠ ReplicaSet<br/>æ”¯æŒå¿«é€Ÿå›æ»¾
```

**æ›´æ–°ç­–ç•¥é…ç½®ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 10
  
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2
      maxUnavailable: 1
  
  revisionHistoryLimit: 5
  
  progressDeadlineSeconds: 600
  
  template:
    spec:
      containers:
      - name: nginx
        image: nginx:1.27
```

**åƒæ•¸èªªæ˜ï¼š**
- `maxSurge`ï¼šå…è¨±è¶…å‡ºæœŸæœ›å‰¯æœ¬æ•¸çš„ Pod æ•¸é‡ï¼ˆå¯ç‚ºæ•¸å­—æˆ–ç™¾åˆ†æ¯”ï¼‰
- `maxUnavailable`ï¼šå…è¨±ä¸å¯ç”¨çš„ Pod æ•¸é‡
- `revisionHistoryLimit`ï¼šä¿ç•™å¤šå°‘å€‹èˆŠ ReplicaSetï¼ˆç”¨æ–¼å›æ»¾ï¼‰
- `progressDeadlineSeconds`ï¼šæ›´æ–°è¶…æ™‚æ™‚é–“

**å¸¸ç”¨æ“ä½œï¼š**

```bash
kubectl rollout status deployment/nginx
kubectl rollout history deployment/nginx
kubectl rollout undo deployment/nginx
kubectl rollout undo deployment/nginx --to-revision=2

kubectl set image deployment/nginx nginx=nginx:1.28
kubectl scale deployment/nginx --replicas=5

kubectl patch deployment nginx -p '{"spec":{"replicas":3}}'
```

### 4.3 Service

**Service é¡å‹èˆ‡ç”¨é€”ï¼š**

```mermaid
graph TB
    subgraph "ClusterIPï¼ˆé›†ç¾¤å…§éƒ¨ï¼‰"
        C[ClusterIP Service<br/>10.96.0.100:80]
        C --> P1[Pod 1]
        C --> P2[Pod 2]
    end
    
    subgraph "NodePortï¼ˆæš´éœ²åˆ°ç¯€é»ï¼‰"
        N[NodePort Service<br/>:30080]
        N --> C
    end
    
    subgraph "LoadBalancerï¼ˆé›²ç«¯è² è¼‰å‡è¡¡ï¼‰"
        L[External LB<br/>34.123.45.67]
        L --> N
    end
    
    External[å¤–éƒ¨ç”¨æˆ¶] --> L
    Internal[é›†ç¾¤å…§æœå‹™] --> C
    
    style C fill:#9cf
    style N fill:#fc9
    style L fill:#f9c
```

**å®Œæ•´ Service é…ç½®ï¼š**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: webapp
  labels:
    app: webapp
spec:
  type: ClusterIP
  
  selector:
    app: webapp
    tier: frontend
  
  ports:
  - name: http
    port: 80
    targetPort: 8080
    protocol: TCP
  
  - name: metrics
    port: 9090
    targetPort: metrics
  
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 3600
  
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
```

**Service ç™¼ç¾æ©Ÿåˆ¶ï¼š**

```mermaid
graph LR
    subgraph "æœå‹™ç™¼ç¾"
        A[DNS æŸ¥è©¢]
        B[ç’°å¢ƒè®Šé‡]
    end
    
    A --> C[webapp.default.svc.cluster.local]
    B --> D[WEBAPP_SERVICE_HOST<br/>WEBAPP_SERVICE_PORT]
    
    C --> E[Service ClusterIP]
    D --> E
    
    E --> F[Endpoints]
    F --> G[Pod 1: 192.168.1.10:8080]
    F --> H[Pod 2: 192.168.1.11:8080]
    
    style A fill:#9cf
    style B fill:#fc9
```

**é–‹ç™¼è€…æœ€ä½³å¯¦è¸ï¼š**

1. **ä½¿ç”¨ DNS åç¨±ï¼š**
   ```yaml
   env:
   - name: DB_HOST
     value: "postgres.database.svc.cluster.local"
   ```

2. **å®šç¾©å‘½åç«¯å£ï¼š**
   ```yaml
   ports:
   - name: http
     containerPort: 8080
   ```
   Service å¯ä½¿ç”¨åç¨±å¼•ç”¨ï¼š`targetPort: http`

3. **å¥åº·æª¢æŸ¥èˆ‡ Endpointsï¼š**
   - åªæœ‰é€šé readinessProbe çš„ Pod æ‰æœƒåŠ å…¥ Endpoints
   - ç¢ºä¿ Service åªè½‰ç™¼æµé‡åˆ°å¥åº· Pod

### 4.4 Namespace

**Namespace ç”¨é€”ï¼š**

```mermaid
graph TB
    subgraph "Kubernetes Cluster"
        subgraph "default"
            D1[Deployment: webapp]
            S1[Service: webapp]
        end
        
        subgraph "development"
            D2[Deployment: webapp]
            S2[Service: webapp]
        end
        
        subgraph "production"
            D3[Deployment: webapp]
            S3[Service: webapp]
        end
        
        subgraph "kube-system"
            K1[CoreDNS]
            K2[kube-proxy]
        end
    end
    
    style default fill:#9cf
    style development fill:#fc9
    style production fill:#f96
    style kube-system fill:#ccc
```

**è³‡æºéš”é›¢ï¼š**

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: dev-quota
  namespace: development
spec:
  hard:
    requests.cpu: "10"
    requests.memory: 20Gi
    limits.cpu: "20"
    limits.memory: 40Gi
    persistentvolumeclaims: "10"
    pods: "50"
```

**æœ€ä½³å¯¦è¸ï¼š**
- ä½¿ç”¨ namespace å€åˆ†ç’°å¢ƒï¼ˆdevã€stagingã€prodï¼‰
- ä½¿ç”¨ namespace å€åˆ†åœ˜éšŠæˆ–é …ç›®
- ç‚ºæ¯å€‹ namespace è¨­ç½®è³‡æºé…é¡
- ä½¿ç”¨ RBAC é™åˆ¶ namespace è¨ªå•æ¬Šé™

---

## 5. é–‹ç™¼è€…æ•…éšœæ’æŸ¥æµç¨‹

### 5.1 Pod ç•°å¸¸æ’æŸ¥

```mermaid
flowchart TD
    A[Pod ç•°å¸¸] --> B{kubectl get pod}
    B --> C{æª¢æŸ¥ STATUS}
    
    C -->|Pending| D[kubectl describe pod]
    D --> E{Events é¡¯ç¤º?}
    E -->|èª¿åº¦å¤±æ•—| F[æª¢æŸ¥è³‡æº/è¦ªå’Œæ€§]
    E -->|é¡åƒæ‹‰å–å¤±æ•—| G[æª¢æŸ¥é¡åƒåç¨±/æ¬Šé™]
    
    C -->|CrashLoopBackOff| H[kubectl logs pod]
    H --> I[æª¢æŸ¥æ‡‰ç”¨æ—¥èªŒ]
    I --> J[kubectl logs pod --previous]
    
    C -->|ImagePullBackOff| K[kubectl describe pod]
    K --> L[æª¢æŸ¥é¡åƒå€‰åº«é…ç½®]
    
    C -->|Running ä½†ç•°å¸¸| M[kubectl exec -it pod -- sh]
    M --> N[æ‰‹å‹•èª¿è©¦]
    
    C -->|Error/Completed| O[kubectl logs pod]
    
    style C fill:#fc9
    style I fill:#9cf
    style N fill:#9cf
```

### 5.2 å¸¸ç”¨èª¿è©¦å‘½ä»¤

```bash
kubectl get pods -o wide
kubectl get pods --show-labels
kubectl get pods -l app=nginx

kubectl describe pod <pod-name>

kubectl logs <pod-name>
kubectl logs <pod-name> -c <container-name>
kubectl logs <pod-name> --previous
kubectl logs -f <pod-name>

kubectl exec -it <pod-name> -- /bin/bash
kubectl exec <pod-name> -- ls /data

kubectl port-forward pod/<pod-name> 8080:80
kubectl port-forward svc/<service-name> 8080:80

kubectl get events --sort-by=.metadata.creationTimestamp
kubectl get events --field-selector involvedObject.name=<pod-name>

kubectl top nodes
kubectl top pods
```

### 5.3 ç¶²çµ¡å•é¡Œæ’æŸ¥

```bash
kubectl run debug --rm -it --image=nicolaka/netshoot -- /bin/bash

nslookup webapp.default.svc.cluster.local

curl http://webapp.default.svc.cluster.local

telnet webapp.default.svc.cluster.local 80

traceroute webapp.default.svc.cluster.local
```

---

## 6. å°çµ

æœ¬ç« æ·±å…¥æ¢è¨äº† Kubernetes çš„æ¶æ§‹è¨­è¨ˆèˆ‡æ ¸å¿ƒçµ„ä»¶ï¼š

**æ§åˆ¶å¹³é¢ï¼š**
- âœ… **API Server**ï¼šçµ±ä¸€å…¥å£ï¼ŒRESTful API
- âœ… **etcd**ï¼šç‹€æ…‹å„²å­˜ï¼Œé›†ç¾¤çœŸå¯¦ä¾†æº
- âœ… **Scheduler**ï¼šPod èª¿åº¦ï¼Œè³‡æºåˆ†é…
- âœ… **Controller Manager**ï¼šæ§åˆ¶è¿´è·¯ï¼Œç‹€æ…‹èª¿å’Œ

**å·¥ä½œç¯€é»ï¼š**
- âœ… **Kubelet**ï¼šç¯€é»ä»£ç†ï¼ŒPod ç”Ÿå‘½é€±æœŸç®¡ç†
- âœ… **Container Runtime**ï¼šå®¹å™¨é‹è¡Œæ™‚ï¼ˆcontainerd/CRI-Oï¼‰
- âœ… **kube-proxy**ï¼šç¶²è·¯ä»£ç†ï¼ŒService è² è¼‰å‡è¡¡

**æ ¸å¿ƒ API ç‰©ä»¶ï¼š**
- âœ… **Pod**ï¼šæœ€å°èª¿åº¦å–®ä½
- âœ… **Deployment**ï¼šç„¡ç‹€æ…‹æ‡‰ç”¨ç®¡ç†
- âœ… **Service**ï¼šæœå‹™ç™¼ç¾èˆ‡è² è¼‰å‡è¡¡
- âœ… **Namespace**ï¼šè³‡æºéš”é›¢

ä¸‹ä¸€ç« å°‡å­¸ç¿’å¦‚ä½•æ­å»ºæœ¬åœ°é–‹ç™¼ç’°å¢ƒï¼Œä½¿ç”¨ Kind/k3d å’Œ Skaffold æå‡é–‹ç™¼æ•ˆç‡ã€‚
